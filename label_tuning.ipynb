{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70cec405",
   "metadata": {},
   "source": [
    "\n",
    "# Tune side model"
   ]
  },
  {
   "cell_type": "code",
   "id": "7cf4d36a",
   "metadata": {},
   "source": [
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from jesse import helpers, research\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from custom_indicators.all_features import feature_bundle\n",
    "from offline.labeling.labeling import TripleBarrierLabeler, expand_labels\n",
    "\n",
    "_, trading_3m = research.get_candles(\n",
    "    \"Binance Perpetual Futures\",\n",
    "    \"BTC-USDT\",\n",
    "    \"3m\",\n",
    "    helpers.date_to_timestamp(\"2020-06-01\"),\n",
    "    helpers.date_to_timestamp(\"2025-01-31\"),\n",
    "    warmup_candles_num=0,\n",
    "    caching=False,\n",
    "    is_for_jesse=False,\n",
    ")\n",
    "_, trading_15m = research.get_candles(\n",
    "    \"Binance Perpetual Futures\",\n",
    "    \"BTC-USDT\",\n",
    "    \"15m\",\n",
    "    helpers.date_to_timestamp(\"2020-06-01\"),\n",
    "    helpers.date_to_timestamp(\"2025-01-31\"),\n",
    "    warmup_candles_num=0,\n",
    "    caching=False,\n",
    "    is_for_jesse=False,\n",
    ")\n",
    "_, trading_1h = research.get_candles(\n",
    "    \"Binance Perpetual Futures\",\n",
    "    \"BTC-USDT\",\n",
    "    \"1h\",\n",
    "    helpers.date_to_timestamp(\"2020-06-01\"),\n",
    "    helpers.date_to_timestamp(\"2025-01-31\"),\n",
    "    warmup_candles_num=0,\n",
    "    caching=False,\n",
    "    is_for_jesse=False,\n",
    ")\n",
    "\n",
    "features_3m = feature_bundle(trading_3m, sequential=True)\n",
    "features_3m = pd.DataFrame(\n",
    "    {f\"3m_{k}\": v for k, v in features_3m.items()},\n",
    "    index=pd.DatetimeIndex([helpers.timestamp_to_time(i) for i in trading_3m[:, 0]]),\n",
    ")\n",
    "features_3m = features_3m.resample(\"15min\").agg(\n",
    "    {k: \"last\" for k in features_3m.columns}\n",
    ")\n",
    "features_15m = feature_bundle(trading_15m, sequential=True)\n",
    "features_15m = pd.DataFrame(\n",
    "    {f\"15m_{k}\": v for k, v in features_15m.items()},\n",
    "    index=pd.DatetimeIndex([helpers.timestamp_to_time(i) for i in trading_15m[:, 0]]),\n",
    ")\n",
    "features_1h = feature_bundle(trading_1h, sequential=True)\n",
    "features_1h = pd.DataFrame(\n",
    "    {f\"1h_{k}\": v for k, v in features_1h.items()},\n",
    "    index=pd.DatetimeIndex([helpers.timestamp_to_time(i) for i in trading_1h[:, 0]]),\n",
    ")\n",
    "features_1h = (\n",
    "    features_1h.resample(\"15min\").agg({k: \"last\" for k in features_1h.columns}).ffill()\n",
    ")\n",
    "\n",
    "df_features = pd.concat([features_3m, features_15m, features_1h], axis=1)\n",
    "print(df_features.shape)\n",
    "\n",
    "\n",
    "def get_side_label(candles, num_hours, target_ret, pt_sl):\n",
    "    labeler = TripleBarrierLabeler(\n",
    "        candles, num_hours=num_hours, num_minutes=1, verbose=False\n",
    "    )\n",
    "    side_labels = labeler.side_labels(pt=pt_sl, sl=pt_sl, target_ret=target_ret)\n",
    "    candle_df = expand_labels(side_labels, candles, fill=0)\n",
    "    return candle_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "597898ab",
   "metadata": {},
   "source": [
    "df_features.to_parquet(\"data/features.parquet\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ef376ba1",
   "metadata": {},
   "source": [
    "def objective(trial):\n",
    "    label_encoder = LabelBinarizer()\n",
    "    num_hours = trial.suggest_int(\"num_hours\", 1, 24)\n",
    "    target_ret = trial.suggest_float(\"target_ret\", 0.0005, 0.05)\n",
    "    pt_sl = trial.suggest_float(\"pt_sl\", 0.1, 3)\n",
    "    label_df = get_side_label(trading_15m, num_hours, target_ret, pt_sl)\n",
    "    label_df = label_df.iloc[240:]\n",
    "    side_features = df_features.iloc[240:]\n",
    "    valid_mask = label_df[\"ret\"].notna()\n",
    "    label_df = label_df[valid_mask]\n",
    "    side_features = side_features[valid_mask]\n",
    "\n",
    "    train_test_split_point = int(len(label_df) * 0.75)\n",
    "    train_features = side_features.iloc[:train_test_split_point]\n",
    "    test_features = side_features.iloc[train_test_split_point:]\n",
    "    train_labels = label_df.iloc[:train_test_split_point]\n",
    "    test_labels = label_df.iloc[train_test_split_point:]\n",
    "\n",
    "    train_labels = train_labels[\"bin\"].astype(int)\n",
    "    test_labels = test_labels[\"bin\"].astype(int)\n",
    "    if test_labels.nunique() <= 1:\n",
    "        return 0\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"multiclassova\",\n",
    "        \"num_class\": 3,\n",
    "        \"num_threads\": -1,\n",
    "        \"verbose\": -1,\n",
    "        \"boosting\": \"gbdt\",\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 31, 200),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 30, 100),\n",
    "    }\n",
    "    dtrain = lgb.Dataset(train_features, train_labels)\n",
    "    # dtest = lgb.Dataset(test_features, test_labels)\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=trial.suggest_int(\"num_boost_round\", 300, 800),\n",
    "    )\n",
    "    label_encoder.fit(train_labels)\n",
    "    pred_proba = model.predict(test_features)\n",
    "    pred_labels = label_encoder.transform(np.argmax(pred_proba, axis=1) - 1)\n",
    "    f1_array = f1_score(label_encoder.transform(test_labels), pred_labels, average=None)\n",
    "    return np.mean(f1_array)\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    pruner=optuna.pruners.PatientPruner(optuna.pruners.MedianPruner(), patience=2),\n",
    "    sampler=optuna.samplers.TPESampler(),\n",
    ")\n",
    "study.optimize(objective, n_trials=500, show_progress_bar=True, n_jobs=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "02acccd1",
   "metadata": {},
   "source": [
    "from jesse import helpers, research\n",
    "\n",
    "from offline.labeling.labeling import TripleBarrierLabeler, expand_labels\n",
    "\n",
    "warmup_3m, trading_3m = research.get_candles(\n",
    "    \"Binance Perpetual Futures\",\n",
    "    \"BTC-USDT\",\n",
    "    \"3m\",\n",
    "    helpers.date_to_timestamp(\"2020-06-01\"),\n",
    "    helpers.date_to_timestamp(\"2025-01-31\"),\n",
    "    warmup_candles_num=0,\n",
    "    caching=False,\n",
    "    is_for_jesse=False,\n",
    ")\n",
    "\n",
    "num_minutes = 10\n",
    "pt_sl = 0.9656765406603607\n",
    "target_ret = 0.005978786042921383\n",
    "labeler = TripleBarrierLabeler(trading_3m, num_minutes=10, verbose=True)\n",
    "side_labels = labeler.side_labels(pt=pt_sl, sl=pt_sl, target_ret=target_ret)\n",
    "print(side_labels[\"bin\"].value_counts().sort_index().to_numpy())\n",
    "candle_df = expand_labels(side_labels, trading_3m, fill=0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fdca2ef2",
   "metadata": {},
   "source": [
    "candle_df.to_parquet(\"data/label_side.parquet\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0ba05ed4",
   "metadata": {},
   "source": [
    "# Tune meta model"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from jesse import helpers, research\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from custom_indicators.all_features import feature_bundle\n",
    "from custom_indicators.selection import SIDE_1M, SIDE_3M, SIDE_15M\n",
    "from offline.labeling.labeling import TripleBarrierLabeler, expand_labels\n",
    "\n",
    "warmup_1m, trading_1m = research.get_candles(\n",
    "    \"Binance Perpetual Futures\",\n",
    "    \"BTC-USDT\",\n",
    "    \"1m\",\n",
    "    helpers.date_to_timestamp(\"2020-06-01\"),\n",
    "    helpers.date_to_timestamp(\"2025-01-31\"),\n",
    "    warmup_candles_num=0,\n",
    "    caching=False,\n",
    "    is_for_jesse=False,\n",
    ")\n",
    "warmup_3m, trading_3m = research.get_candles(\n",
    "    \"Binance Perpetual Futures\",\n",
    "    \"BTC-USDT\",\n",
    "    \"3m\",\n",
    "    helpers.date_to_timestamp(\"2020-06-01\"),\n",
    "    helpers.date_to_timestamp(\"2025-01-31\"),\n",
    "    warmup_candles_num=0,\n",
    "    caching=False,\n",
    "    is_for_jesse=False,\n",
    ")\n",
    "warmup_15m, trading_15m = research.get_candles(\n",
    "    \"Binance Perpetual Futures\",\n",
    "    \"BTC-USDT\",\n",
    "    \"15m\",\n",
    "    helpers.date_to_timestamp(\"2020-06-01\"),\n",
    "    helpers.date_to_timestamp(\"2025-01-31\"),\n",
    "    warmup_candles_num=0,\n",
    "    caching=False,\n",
    "    is_for_jesse=False,\n",
    ")\n",
    "\n",
    "features_1m = feature_bundle(trading_1m, sequential=True)\n",
    "features_1m = pd.DataFrame(\n",
    "    {f\"1m_{k}\": v for k, v in features_1m.items()},\n",
    "    index=pd.DatetimeIndex([helpers.timestamp_to_time(i) for i in trading_1m[:, 0]]),\n",
    ")\n",
    "features_1m = features_1m.resample(\"3T\").agg({k: \"last\" for k in features_1m.columns})\n",
    "features_3m = feature_bundle(trading_3m, sequential=True)\n",
    "features_3m = pd.DataFrame(\n",
    "    {f\"3m_{k}\": v for k, v in features_3m.items()},\n",
    "    index=pd.DatetimeIndex([helpers.timestamp_to_time(i) for i in trading_3m[:, 0]]),\n",
    ")\n",
    "features_15m = feature_bundle(trading_15m, sequential=True)\n",
    "features_15m = pd.DataFrame(\n",
    "    {f\"15m_{k}\": v for k, v in features_15m.items()},\n",
    "    index=pd.DatetimeIndex([helpers.timestamp_to_time(i) for i in trading_15m[:, 0]]),\n",
    ")\n",
    "features_15m = (\n",
    "    features_15m.resample(\"3T\").agg({k: \"last\" for k in features_15m.columns}).ffill()\n",
    ")\n",
    "\n",
    "df_features = pd.concat([features_1m, features_3m, features_15m], axis=1)\n",
    "print(df_features.shape)\n",
    "\n",
    "side_model = lgb.Booster(model_file=\"custom_indicators/models/model_side.txt\")\n",
    "side_features_col = SIDE_1M + SIDE_3M + SIDE_15M\n",
    "side_model_pred = side_model.predict(df_features[side_features_col])\n",
    "df_features[\"model_side_res\"] = side_model_pred\n",
    "\n",
    "\n",
    "def get_meta_label(candles, target_ret, pt, sl, num_minutes=0, num_hours=0):\n",
    "    labeler = TripleBarrierLabeler(\n",
    "        candles, num_minutes=num_minutes, num_hours=num_hours, verbose=False\n",
    "    )\n",
    "    side_labels = labeler.side_labels(pt=pt, sl=sl, target_ret=target_ret)\n",
    "    side_full_df = expand_labels(side_labels, candles)\n",
    "    side_full_df[\"pred\"] = [1 if i > 0.5 else -1 for i in side_model_pred]\n",
    "    meta_labels = labeler.meta_labels(side_full_df, pt=pt, sl=sl, target_ret=target_ret)\n",
    "    candle_df = expand_labels(meta_labels, candles, fill=0)\n",
    "    return candle_df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "799c4684",
   "metadata": {},
   "source": [
    "def objective(trial):\n",
    "    num_minutes = trial.suggest_int(\"num_minutes\", 10, 120)\n",
    "    target_ret = trial.suggest_float(\"target_ret\", 0.0005, 0.01)\n",
    "    pt = trial.suggest_float(\"pt\", 0.1, 1.2)\n",
    "    sl = trial.suggest_float(\"sl\", 0.1, 1.2)\n",
    "    label_df = get_meta_label(trading_3m, num_minutes, target_ret, pt, sl)\n",
    "\n",
    "    train_test_split_point = int(len(label_df) * 0.8)\n",
    "    train_features = df_features.iloc[:train_test_split_point]\n",
    "    test_features = df_features.iloc[train_test_split_point:]\n",
    "    train_labels = label_df.iloc[:train_test_split_point]\n",
    "    test_labels = label_df.iloc[train_test_split_point:]\n",
    "\n",
    "    train_valid_mask = train_labels[\"ret\"].notna().tolist()\n",
    "    test_valid_mask = test_labels[\"ret\"].notna().tolist()\n",
    "\n",
    "    train_features = train_features[train_valid_mask]\n",
    "    train_labels = train_labels[train_valid_mask][\"bin\"].astype(int)\n",
    "    test_features = test_features[test_valid_mask]\n",
    "    test_labels = test_labels[test_valid_mask][\"bin\"].astype(int)\n",
    "    if test_labels.nunique() <= 1:\n",
    "        return 0\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"binary\",\n",
    "        \"metric\": \"auc\",\n",
    "        \"num_threads\": -1,\n",
    "        \"verbose\": -1,\n",
    "        \"early_stopping_round\": 100,\n",
    "        \"boosting\": \"gbdt\",\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 31, 200),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 30, 100),\n",
    "        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 1e-8, 1),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 20, 200),\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 1),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 1),\n",
    "    }\n",
    "    dtrain = lgb.Dataset(train_features, train_labels)\n",
    "    dtest = lgb.Dataset(test_features, test_labels)\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        valid_sets=[dtest],\n",
    "        num_boost_round=trial.suggest_int(\"num_boost_round\", 300, 800),\n",
    "    )\n",
    "    pred_proba = model.predict(test_features)\n",
    "    auc = roc_auc_score(test_labels, pred_proba, average=\"weighted\")\n",
    "    return auc\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    pruner=optuna.pruners.PatientPruner(optuna.pruners.MedianPruner(), patience=2),\n",
    "    sampler=optuna.samplers.TPESampler(),\n",
    ")\n",
    "study.optimize(objective, n_trials=500, show_progress_bar=True, n_jobs=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5d1a3be18ea82393",
   "metadata": {},
   "source": [
    "{\n",
    "    \"num_minutes\": 12,\n",
    "    \"target_ret\": 0.00999169655418248,\n",
    "    \"pt\": 1.0586409809460318,\n",
    "    \"sl\": 0.6472137540480188,\n",
    "    \"num_leaves\": 43,\n",
    "    \"max_depth\": 71,\n",
    "    \"min_gain_to_split\": 0.5374875726311118,\n",
    "    \"min_data_in_leaf\": 46,\n",
    "    \"lambda_l1\": 0.8426077111660407,\n",
    "    \"lambda_l2\": 0.6195771592283434,\n",
    "    \"num_boost_round\": 707,\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "867f6741",
   "metadata": {},
   "source": [
    "df_meta_label = get_meta_label(\n",
    "    trading_3m, 12, 0.00999169655418248, 1.0586409809460318, 0.6472137540480188\n",
    ")\n",
    "print(df_meta_label.shape)\n",
    "df_meta_label.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d7e69cb5",
   "metadata": {},
   "source": [
    "df_meta_label.to_parquet(\"data/label_meta.parquet\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "93a5ca77",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jesse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
