# Claude SKILL: 置信度切片分析与过滤器配置

## 任务概述

协助用户分析机器学习模型的置信度切片图表，并根据图表特征配置相应的过滤器（filters），以校准模型的多空交易行为。

## 背景知识

### 核心问题
- 机器学习拟合的是**面板数据**，而量化投资需要考虑**时序性**
- 即便模型拥有较好的拟合效果，在时序上依然存在亏损的可能性

### 解决方案
- 通过置信度切片在测试集上对模型预测概率进行细粒度切分
- 结合实际盈亏制作当前粒度的真实盈亏曲线
- 通过校准后的多个模型投票决定交易行为
  - 所有模型一致预期多头/空头 → 开启相应持仓
  - 模型预测有分歧 → 空仓（利用分歧减少交易次数并降低磨损）

## 工作流程

### 1. 理解用户提供的信息

#### 典型用户请求格式
用户通常会这样提出请求：
> "请帮我完成 temp/c_L3_N1 的置信度切片图片分析"

或
> "@temp/r_L5_N2 请帮我完成置信度切片分析"

#### 模型命名约定（自动解析规则）

从路径 `temp/{MODEL_TYPE}_L{LAG}_N{PRED_NEXT}` 中提取信息：

**命名格式：** `{类型}_L{LAG}_N{PRED_NEXT}`

**参数解析：**
- **第一部分（类型）：**
  - `c` → 分类模型（Classification）
  - `r` → 回归模型（Regression）

- **L{数字}：** log return lag
  - 例如：`L3` → LAG=3, `L5` → LAG=5

- **N{数字}：** 预测未来第N个标签
  - 例如：`N1` → PRED_NEXT=1, `N2` → PRED_NEXT=2

**自动推断默认参数：**

| 模型类型 | LOWER_BOUND | UPPER_BOUND | THRESHOLD | 说明 |
|---------|-------------|-------------|-----------|------|
| 分类 (c) | 0.0 | 1.0 | 0.5 | 输出为概率值 |
| 回归 (r) | -1.0 | 1.0 | 0.0 | 目标永远在[-1,1]，多空分界点为0 |

**解析示例：**
- `temp/c_L3_N1` →
  - MODEL_TYPE = "c"
  - LAG = 3
  - PRED_NEXT = 1
  - LOWER_BOUND = 0.0
  - UPPER_BOUND = 1.0
  - THRESHOLD = 0.5

- `temp/r_L5_N2` →
  - MODEL_TYPE = "r"
  - LAG = 5
  - PRED_NEXT = 2
  - LOWER_BOUND = -1.0
  - UPPER_BOUND = 1.0
  - THRESHOLD = 0.0

#### 工作流程
1. 从用户请求中识别模型路径
2. 解析模型命名，提取参数
3. 根据模型类型自动推断默认参数
4. 读取指定目录下的所有切片图片
5. 开始逐个分析

### 2. 分析置信度切片图表

每张图片包含以下关键信息：
- **切片区间**：`[lower, upper]`，如 [0.84, 0.86]
- **交易方向**：(做多) 或 (做空)
- **样本占比**：该区间样本数占总样本的比例
- **最终收益**：曲线终点的累积盈亏值
- **平均收益**：红色虚线表示的均值
- **曲线形态**：整体走势特征

### 3. 决策准则

**小样本区间判断原则：**
- 虽然总体保守，但对于交易次数较少的区间，**以曲线走向为主要判断依据**
- 即使仅有一两笔交易，只要曲线呈**相对单调**趋势（单调上升或单调下降），即可判定为有效区间
- 单调前提下捕捉到的暴涨暴跌是有价值的信号，应当保留

根据图表特征，做出以下三种决策之一：

#### 决策A: 不干预（良好区间）

**判断标准：**
- ✅ 曲线总体单调向上
- ✅ 平均收益（红色虚线）> 0
- ✅ 最终收益 > 0

**操作：** 无需添加过滤器，模型在此区间预测良好

**示例描述：** "曲线稳定上升，平均收益为正，模型预测准确，保持原有策略"

#### 决策B: 反向操作（反向区间）

**判断标准：**
- ✅ 曲线总体单调向下
- ✅ 平均收益（红色虚线）< 0
- ✅ 最终收益 < 0

**操作：** 添加反向过滤器
```python
mc.add_reverse_filter(lower_bound, upper_bound)
```

**示例描述：** "曲线持续下降，平均收益为负，模型预测与实际相反，需要添加反向操作过滤器"

#### 决策C: 放弃交易（随机区间）

**判断标准（满足任一即可）：**
- ✅ 样本占比 = 0（无交易数据）
- ✅ 曲线呈S型围绕零轴波动（难以判定方向）
- ✅ 曲线呈半圆形（前半段亏损，后半段盈利，或相反）
- ✅ 平均收益接近0，但波动剧烈

**操作：** 添加空仓过滤器
```python
mc.add_giveup_filter(lower_bound, upper_bound)
```

**示例描述：** "曲线呈S型波动/半圆形走势/无交易数据，模型预测随机性过大，应放弃此区间交易"

### 4. 批量处理流程（双重验证机制）

#### 核心策略：双重分析 + 裁判机制

由于 child agent 对图表走势的判断存在随机性，**必须采用双重验证机制**以确保判定准确性。

**核心原则：**
- 对所有切片图片进行**两轮完整的独立分析**
- 两次结论一致 → 直接采纳
- 两次结论不一致 → 启动裁判 agent 综合判定
- 裁判无法确定 → 保守策略，采用 giveup

---

**完整工作流程：**

#### **阶段1：准备与检查**
1. 解析模型参数（从路径提取，如 `temp/c_L3_N1`）
2. 扫描目标目录，获取所有切片图片列表（使用 Glob 工具）
3. 检查进度文件是否存在：
   - `temp/{模型名称}_round1.jsonl` (第一轮分析)
   - `temp/{模型名称}_round2.jsonl` (第二轮分析)
   - `temp/{模型名称}_final.jsonl` (最终结果)
4. 如果用户要求"重新分析"：
   - 删除所有临时文件
   - 重新开始双重分析

#### **阶段2A：第一轮并行分析**
1. 将所有图片分组（建议每组5-10张）
2. 使用 Task tool 启动多个 child agent 并行处理
3. 每个 child agent：
   - 读取图片
   - 分析曲线特征（最终收益、平均收益、盈利面占比、曲线形态）
   - 做出决策（good/reverse/giveup）
   - 将结果追加到 `temp/{模型名称}_round1.jsonl`
4. 等待所有 child agent 完成
5. **验证JSONL完整性**：
   - 检查每一行JSON格式是否符合规范（必须包含slice/decision/reason/sample_ratio字段）
   - 统计JSONL行数是否等于图片总数
   - 若存在缺失或格式错误，识别缺失的切片，重新分析缺失部分
   - **只有完全一致后才能进入第二轮**

#### **阶段2B：第二轮并行分析**
1. 使用**相同的图片分组**再次启动 child agent
2. 每个 child agent **独立分析**（不参考第一轮结果）
3. 将结果追加到 `temp/{模型名称}_round2.jsonl`
4. 等待所有 child agent 完成
5. **验证JSONL完整性**：
   - 检查每一行JSON格式是否符合规范
   - 统计JSONL行数是否等于图片总数
   - 若存在缺失或格式错误，识别缺失的切片，重新分析缺失部分
   - **只有完全一致后才能进入冲突检查**

#### **阶段3：一致性检查与裁判**
1. 读取两轮分析结果
2. 逐个切片对比两轮决策：

   **情况A：两轮结论一致**
   - 示例：round1=good, round2=good
   - 操作：直接采纳，写入 `temp/{模型名称}_final.jsonl`

   **情况B：两轮结论不一致**
   - 示例：round1=good, round2=giveup
   - 操作：启动裁判 agent 进行综合判定

3. 对所有不一致的切片，启动裁判 child agent：
   - 提供该切片的图片路径
   - 提供两轮分析的决策和理由
   - 要求裁判 agent：
     - 重新读取图片
     - 对比两轮理由的合理性
     - 综合考量数据指标（最终收益、平均收益、盈利面占比）
     - 给出最终判定（good/reverse/giveup）
     - 如果无法确定倾向性 → 采用 **giveup**（保守原则）

4. 将裁判结果写入 `temp/{模型名称}_final.jsonl`

#### **阶段4：汇总与生成**
1. 读取 `temp/{模型名称}_final.jsonl`
2. 按决策类型分类汇总：
   - 良好区间（good）
   - 反向区间（reverse）
   - 放弃区间（giveup）
3. 统计一致性指标：
   - 两轮一致的切片数量
   - 需要裁判的切片数量
   - 裁判采用giveup的数量（说明信号不明确）
4. 生成详细分析报告
5. 在项目根目录生成可执行的配置代码并运行代码保存filter结果
6. 保存filter结果后立即删除配置filter的.py代码

#### 临时文件管理

除非需要重新分析或用户要求清理，否则保留所有临时文件供后续审查。

**文件命名规则：**
- `temp/{模型名称}_round1.jsonl` - 第一轮分析结果
- `temp/{模型名称}_round2.jsonl` - 第二轮分析结果
- `temp/{模型名称}_conflicts.jsonl` - 不一致的切片列表（供裁判使用）
- `temp/{模型名称}_final.jsonl` - 最终采纳的结果

**示例：**
- `temp/c_L3_N1_round1.jsonl`
- `temp/c_L3_N1_round2.jsonl`
- `temp/c_L3_N1_conflicts.jsonl`
- `temp/c_L3_N1_final.jsonl`

---

**第一轮/第二轮分析文件格式（JSONL）：**
```jsonl
{"slice": "[0.02, 0.04]", "decision": "reverse", "reason": "曲线持续下降，最终收益-0.0856，平均收益-0.0421，盈利面38%", "sample_ratio": 0.0148}
{"slice": "[0.04, 0.06]", "decision": "good", "reason": "曲线整体上升，最终收益0.9904，平均收益1.3296，盈利面56.67%", "sample_ratio": 0.0257}
```

**不一致列表文件格式（conflicts.jsonl）：**
```jsonl
{"slice": "[0.02, 0.04]", "round1": {"decision": "giveup", "reason": "曲线剧烈波动"}, "round2": {"decision": "good", "reason": "最终收益0.4181为正"}, "sample_ratio": 0.0148}
```

**最终结果文件格式（final.jsonl）：**
```jsonl
{"slice": "[0.02, 0.04]", "decision": "good", "reason": "裁判判定：最终收益0.4181，平均收益0.3049，盈利面55.60%，综合评估为good区间", "source": "referee", "sample_ratio": 0.0148}
{"slice": "[0.04, 0.06]", "decision": "good", "reason": "两轮一致：曲线整体上升", "source": "consensus", "sample_ratio": 0.0257}
```

**JSON字段说明：**
- `slice` (string): 切片区间，如 "[0.02, 0.04]"
- `decision` (string): 决策类型，"good" / "reverse" / "giveup"
- `reason` (string): 决策理由简述（包含关键指标）
- `sample_ratio` (float): 样本占比（0-1之间）
- `source` (string): 决策来源，"consensus"（两轮一致）/ "referee"（裁判判定）
- `round1/round2` (object): 各轮的决策和理由（仅在conflicts.jsonl中）

#### 配置代码生成示例

```python
from strategies.BinanceBtcDeapV1Voting.models.config import LGBMContainer

# 初始化模型容器（参数从路径自动解析）
mc = LGBMContainer(
    model_type="c",  # 从 temp/c_L3_N1 解析
    lag=3,           # 从路径解析
    pred_next=1,     # 从路径解析
    threshold=0.5,   # 根据模型类型自动推断
)

print(mc.MODEL_NAME)  # 验证: model_c_L3_N1

# 添加反向操作过滤器（从临时文件汇总）
mc.add_reverse_filter(0.02, 0.04)
mc.add_reverse_filter(0.06, 0.08)
# ...

# 添加空仓过滤器（从临时文件汇总）
mc.add_giveup_filter(0.48, 0.50)
mc.add_giveup_filter(0.50, 0.52)
# ...

# 保存过滤器配置
mc.save_filters()
print(f"过滤器配置已保存至: {mc.filter_file_path}")
```


## 核心要求

1. **双重验证机制**：必须执行两轮独立分析，不一致切片由裁判判定
2. **并行处理**：使用Task tool启动child agents并行分析（每组5-10张）
3. **JSONL完整性验证**：每轮分析后必须检查JSONL文件，确保图片数量与分析条目数量完全一致，格式严格符合规范，验证通过后才能推进下一阶段
4. **保守原则**：裁判无法确定时采用giveup，样本占比为0自动giveup
5. **完整覆盖**：确保所有50张切片都被分析并纳入final.jsonl
6. **数值优先**：裁判判定基于数值指标（最终收益、平均收益、盈利面），曲线形态为辅助
