{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64d6aa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "\n",
    "\n",
    "USE_STANDARDIZATION = 0       #####  1 做标准化，0 不做标准化\n",
    "CV_TYPE = 2       ##### 交叉验证 1 KFold，2 时间顺序\n",
    "FOLD_NUM = 5      ##### 折数\n",
    "\n",
    "dataset_s = pd.read_csv('./test/RB99_1m_Turnover_31000_12120_591.csv_tz80_Train_10877_p.csv')   ####### 训练集文件\n",
    "dataset = dataset_s\n",
    "\n",
    "num_xunlian = len(dataset_s)\n",
    "data_1_size = 1213    ###### 测试数据行数  ###############\n",
    "m_size = 25     ####### 测试多少个月 #######\n",
    "buy = 1     ##### 多 ###################\n",
    "sell = 0     ##### 空 ####################\n",
    "rrr = 0.25     ###### 系数 ###################\n",
    "m = 1000       ###### 总资金 ###################\n",
    "\n",
    "\n",
    "### 模型训练指标保存\n",
    "\n",
    "res1 = []\n",
    "res2 = []\n",
    "res3 = []\n",
    "res4 = []\n",
    "res5 = []\n",
    "res6 = []\n",
    "res7 = []\n",
    "resP = []\n",
    "resR = []\n",
    "resF = []\n",
    "\n",
    "\n",
    "### 交叉验证\n",
    "\n",
    "if CV_TYPE == 1:\n",
    "    ### KFold\n",
    "    cv = KFold(n_splits=FOLD_NUM, shuffle=True, random_state=369)\n",
    "else:\n",
    "    ### 时间顺序\n",
    "    cv = TimeSeriesSplit(n_splits=FOLD_NUM)\n",
    "\n",
    "for j in range(1,21):   ########## 从n维训练到多少维\n",
    "    num = j\n",
    "    \n",
    "    X = dataset.drop('A0', axis=1)\n",
    "    y = dataset['A0']\n",
    "    \n",
    "    ### 是否标准化\n",
    "    if USE_STANDARDIZATION == 1:\n",
    "        ### 做标准化\n",
    "        scaler = StandardScaler()\n",
    "        X_processed = scaler.fit_transform(X)  ### 标准化后的特征\n",
    "    else:\n",
    "        ### 不做标准化\n",
    "        scaler = None  ### 无需scaler\n",
    "        X_processed = X.copy()  ### 原始特征\n",
    "    \n",
    "    ### PCA降维\n",
    "    pca = PCA(n_components=num, random_state=369)\n",
    "    X_pca = pca.fit_transform(X_processed)\n",
    "    \n",
    "    ### XGBoost模型\n",
    "    model = xgb.XGBRegressor(random_state=369)\n",
    "    \n",
    "    ### 定义参数网格进行调优\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'max_depth': [3, 5]\n",
    "    }\n",
    "    \n",
    "    ### 网格搜索优化模型使用指定的交叉验证\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=cv, scoring='neg_root_mean_squared_error', n_jobs=-1)\n",
    "    grid_search.fit(X_pca, y)\n",
    "    \n",
    "    ### 获取最佳模型\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    ### 交叉验证评估模型\n",
    "    if CV_TYPE == 1:\n",
    "        ### KFold可以直接使用cross_val_score\n",
    "        cv_mse = -cross_val_score(best_model, X_pca, y, cv=cv, scoring='neg_mean_squared_error')\n",
    "        cv_r2 = cross_val_score(best_model, X_pca, y, cv=cv, scoring='r2')\n",
    "    else:\n",
    "        ### 时间顺序验证需要循环计算指标\n",
    "        cv_mse = []\n",
    "        cv_r2 = []\n",
    "        \n",
    "        for train_idx, test_idx in cv.split(X_pca):\n",
    "            ### 在训练集上训练模型\n",
    "            best_model.fit(X_pca[train_idx], y.iloc[train_idx])\n",
    "            ### 在测试集上预测\n",
    "            y_pred = best_model.predict(X_pca[test_idx])\n",
    "            ### 计算指标\n",
    "            mse = mean_squared_error(y.iloc[test_idx], y_pred)\n",
    "            r2 = r2_score(y.iloc[test_idx], y_pred)\n",
    "            cv_mse.append(mse)\n",
    "            cv_r2.append(r2)\n",
    "        \n",
    "        cv_mse = np.array(cv_mse)\n",
    "        cv_r2 = np.array(cv_r2)\n",
    "    \n",
    "    ### 计算RMSE\n",
    "    cv_rmse = np.sqrt(cv_mse)\n",
    "    \n",
    "    ### 评估指标\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Metric': ['MSE', 'RMSE', 'R2'],\n",
    "        'Mean': [cv_mse.mean(), cv_rmse.mean(), cv_r2.mean()],\n",
    "        'Std': [cv_mse.std(), cv_rmse.std(), cv_r2.std()]\n",
    "    })\n",
    "    \n",
    "    ### 保存结果\n",
    "    metrics_df.to_csv('./temp/' + str(j) + 'r.csv', index=False)\n",
    "    \n",
    "    ### 保存最终模型\n",
    "    pipeline = {\n",
    "        'use_standardization': USE_STANDARDIZATION,  ### 记录是否做了标准化\n",
    "        'scaler': scaler,  ### 若未做标准化，scaler为None\n",
    "        'pca': pca,\n",
    "        'model': best_model,\n",
    "        'cv_type': CV_TYPE,  ### 记录交叉验证类型\n",
    "        'fold_num': FOLD_NUM  ### 记录折数\n",
    "    }\n",
    "    joblib.dump(pipeline, './temp/' + str(num) + 'x.pkl')\n",
    "    \n",
    "    ### 加载测试数据\n",
    "    data = pd.read_csv('./test/RB99_1m_Turnover_31000_12120_591.csv_tz80_Test_1213_PCA.csv')   ###### 测试集数据\n",
    "    \n",
    "    ### 应用模型进行推理\n",
    "    pipeline = joblib.load('./temp/' + str(num) + 'x.pkl')\n",
    "    ### 获取状态\n",
    "    use_std = pipeline['use_standardization']\n",
    "    scaler = pipeline['scaler']\n",
    "    pca = pipeline['pca']\n",
    "    model = pipeline['model']\n",
    "    \n",
    "    ### 处理测试集特征\n",
    "    X_test = data.drop('A0', axis=1) if 'A0' in data.columns else data\n",
    "    if use_std == 1:\n",
    "        ### 训练时做了标准化，测试时也做\n",
    "        X_test_processed = scaler.transform(X_test)\n",
    "    else:\n",
    "        ### 训练时没做标准化，测试时直接用原始特征\n",
    "        X_test_processed = X_test.copy()\n",
    "    \n",
    "    ### 测试集PCA降维\n",
    "    X_test_pca = pca.transform(X_test_processed)\n",
    "    predictions = model.predict(X_test_pca)\n",
    "    \n",
    "    ### 推理结果\n",
    "    data['prediction_label'] = predictions\n",
    "    n_preds = data['prediction_label'][num_xunlian:(num_xunlian+data_1_size)]\n",
    "    n_preds = n_preds.reset_index(drop=True)\n",
    "    \n",
    "    ### 保存预测结果\n",
    "    with open('./temp/' + str(num) + 'x.txt', 'a') as Note:\n",
    "        for i in range(0, data_1_size):\n",
    "            Note.write(str(n_preds[i]) + '\\n')\n",
    "            \n",
    "            \n",
    "    ### 处理信号\n",
    "    file_name = './temp/Show.csv'\n",
    "    df = pd.read_csv(file_name)\n",
    "    path = './temp/' + str(j) + 'x.txt'\n",
    "    df2 = pd.read_csv(path, header=None, names=['state_x'])\n",
    "    df['state_x'] = df2['state_x']\n",
    "    \n",
    "    df.loc[df['state_x'] > 0, 'low'] = 1\n",
    "    df.loc[df['state_x'] < 0, 'low'] = 0\n",
    "    \n",
    "    ### 过滤信号(可选)  ###########################################\n",
    "    ft = 0.6\n",
    "    df.loc[df['state_x'] > ft, 'low'] = 1\n",
    "    df.loc[(0 < df['state_x']) & (df['state_x'] <= ft), 'low'] = 2\n",
    "    df.loc[df['state_x'] < -ft, 'low'] = 0\n",
    "    df.loc[(0 > df['state_x']) & (df['state_x'] >= -ft), 'low'] = 2\n",
    "    \n",
    "    ################################################################\n",
    "        \n",
    "    df.to_csv('./temp/' + str(j) + 'x.csv', index=False)\n",
    "\n",
    "    file_name = './temp/' + str(j) + 'x.csv'\n",
    "    data_1_new = pd.read_csv(file_name)\n",
    "    \n",
    "\n",
    "    if buy == 0:\n",
    "        for i in range(0, data_1_size):\n",
    "            if data_1_new.loc[i, 'low'] == 1:\n",
    "                data_1_new.loc[i, 'volume'] = data_1_new.loc[i, 'volume'] * -1\n",
    "    else:\n",
    "        for i in range(0, data_1_size):\n",
    "            if data_1_new.loc[i, 'low'] == 0:\n",
    "                data_1_new.loc[i, 'volume'] = data_1_new.loc[i, 'volume'] * -1\n",
    "            if data_1_new.loc[i, 'low'] == 2:  ###### 过滤信号，2为不持仓\n",
    "                data_1_new.loc[i, 'volume'] = 0\n",
    "    \n",
    "\n",
    "    data_1_new['high'] = data_1_new['volume'].cumsum()\n",
    "    data_1_new['open'] = rrr * data_1_new['high'] / m\n",
    "    \n",
    "    \n",
    "    ######################################################################################################\n",
    "\n",
    "    ### 胜率\n",
    "    wp_win = data_1_new['volume'] > 0\n",
    "    wp_lost = data_1_new['volume'] < 0\n",
    "    wp_nothing = data_1_new['volume'] == 0\n",
    "\n",
    "    wp_win_a = wp_win.sum()            \n",
    "    wp_lost_a = wp_lost.sum()\n",
    "    wp_nothing_a = wp_nothing.sum()\n",
    "\n",
    "    ### 盈亏比\n",
    "    rrr_win = data_1_new.loc[wp_win, 'volume'].sum()\n",
    "    rrr_lost = data_1_new.loc[wp_lost, 'volume'].sum()\n",
    "\n",
    "    ##############################################################################################\n",
    "    ###### 计算回撤数据\n",
    "    data_1_new['cum_max_open'] = data_1_new['open'].cummax()  \n",
    "    data_1_new['down'] = data_1_new['open'] - data_1_new['cum_max_open']  \n",
    "    data_1_new['down'] = data_1_new['down'].clip(upper=0)  \n",
    "\n",
    "    ##############################################################################################\n",
    "    ###### 计算回撤面积\n",
    "    downarea = data_1_new['down'].sum()\n",
    "\n",
    "    ##############################################################################################\n",
    "    ### 二级模型预留\n",
    "    \n",
    "\n",
    "    data_1_new['re'] = data_1_new['close'].pct_change() * 100\n",
    "    data_1_new['real'] = (data_1_new['close'] >= data_1_new['close'].shift(1)).astype(int)\n",
    "    data_1_new.loc[0, 'real'] = 0 \n",
    "\n",
    "    if buy == 0:\n",
    "        data_1_new['real_lab'] = np.where(\n",
    "            data_1_new['low'] != data_1_new['real'], \n",
    "            'G', 'N'\n",
    "        )\n",
    "    else:\n",
    "        data_1_new['real_lab'] = np.where(\n",
    "            data_1_new['low'] == data_1_new['real'], \n",
    "            'G', 'N'\n",
    "        )\n",
    "\n",
    "    data_1_new.loc[0, 'real_lab'] = 'G' \n",
    "\n",
    "    file_name = './temp/Show.csv'\n",
    "    df = pd.read_csv(file_name)        \n",
    "    data_1_new['show'] = df['low']\n",
    "\n",
    "    data_1_new['show_lab'] = np.where(\n",
    "        data_1_new['low'] == data_1_new['show'], \n",
    "        'G', 'N'\n",
    "    )\n",
    "\n",
    "    data_1_new.loc[0, 'show_lab'] = 'G'  \n",
    "\n",
    "    ##############################################################################################\n",
    "\n",
    "\n",
    "    if sell == 0:\n",
    "        data_1_new['re_real'] = np.where(\n",
    "            data_1_new['low'] == 0, \n",
    "            -data_1_new['re'], \n",
    "            data_1_new['re']\n",
    "        )\n",
    "    else:\n",
    "        data_1_new['re_real'] = np.where(\n",
    "            data_1_new['low'] == 1, \n",
    "            -data_1_new['re'], \n",
    "            data_1_new['re']\n",
    "        )\n",
    "\n",
    "    data_1_new.loc[0, 're_real'] = 0  \n",
    "\n",
    "    ##############################################################################################\n",
    "\n",
    "    ###### 计算夏普比率和索提诺比率\n",
    "    re_real = data_1_new['re_real'][1:]  \n",
    "    mean_re = re_real.mean()\n",
    "    std_re = re_real.std()\n",
    "    sharpe = round(mean_re / std_re * 100 if std_re != 0 else 0, 4)\n",
    "\n",
    "    neg_re = re_real[re_real < 0]\n",
    "    std_neg_re = neg_re.std() if not neg_re.empty else 0\n",
    "    sortino = round(mean_re / std_neg_re * 100 if std_neg_re != 0 else 0, 4)\n",
    "\n",
    "    ##############################################################################################\n",
    "\n",
    "    data_1_new.to_csv('./temp/' + str(j) + 'x.csv', index=False)\n",
    "\n",
    "    ###### 计算最大回撤\n",
    "    cum_max_open = data_1_new['open'].cummax()  ###### 累计最大值\n",
    "    drawdown = cum_max_open - data_1_new['open']  ###### 回撤值\n",
    "    s = np.argmax(drawdown)  ###### 最大回撤结束位置\n",
    "\n",
    "    ###### 确定最大回撤开始位置\n",
    "    if s == 0:\n",
    "        e = 0\n",
    "    else:\n",
    "        e = np.argmax(data_1_new['open'].iloc[:s]) \n",
    "\n",
    "    maxdrawdown = data_1_new['open'].iloc[e] - data_1_new['open'].iloc[s]  ###### 最大回撤\n",
    "    drawdown_days = s - e  ###### 回撤持续周期数\n",
    "    \n",
    "    \n",
    "    start_DAY = data_1_new.index[s] ######开始回撤的日期\n",
    "    end_DAY = data_1_new.index[e] ######结束回撤的日期\n",
    "    start_net_value = data_1_new[data_1_new.index == start_DAY]['open'].values[0] ######开始回撤的净值\n",
    "    end_net_value = data_1_new[data_1_new.index == end_DAY]['open'].values[0] ######结束回撤的净值\n",
    "    fig=plt.figure(figsize=(20,11))  \n",
    "    plt.plot(data_1_new['eob'], data_1_new['open'])\n",
    "    plt.plot([start_DAY, end_DAY], [start_net_value, end_net_value], linestyle='--', color='r')\n",
    "\n",
    "    plt.xticks(range(0,data_1_size,int(data_1_size/m_size))) \n",
    "\n",
    "    plt.legend(['All:' + str(round(data_1_new['open'].iloc[-1]*100,2)) + '%' +\n",
    "                '   ' + str(m_size) + 'm'\n",
    "                '   Year:'+ str(round(data_1_new['open'].iloc[-1]/m_size*100*12,2)) + '%' +\n",
    "                '   CalmarY:'+ str(round((data_1_new['open'].iloc[-1]/m_size*100*12)/(maxdrawdown*100),2)) +\n",
    "                '   WP:' + str(round(wp_win_a/(wp_win_a + wp_lost_a)*100,2)) + '%' +\n",
    "                '   RRR:' + str(round(rrr_win/(rrr_win+abs(rrr_lost))*100,2)) + '%' + ' / ' + str(round(rrr_win/abs(rrr_lost),2)) +\n",
    "                '   T/N:' + str(wp_win_a + wp_lost_a ) + ' / ' + str(wp_nothing_a) +\n",
    "                '   Sharpe:' + str(sharpe) +\n",
    "                '   Sortino:' + str(sortino) +\n",
    "                '   MSE:' + str(round(metrics_df.loc[metrics_df['Metric'] == 'MSE', 'Mean'].values[0], 4)) +\n",
    "                '   RMSE:' + str(round(metrics_df.loc[metrics_df['Metric'] == 'RMSE', 'Mean'].values[0], 4)) +\n",
    "                '   R2:' + str(round(metrics_df.loc[metrics_df['Metric'] == 'R2', 'Mean'].values[0], 4)),\n",
    "\n",
    "                'MD:'+ str(round(maxdrawdown*100,2)) + '%' +\n",
    "                '   DA:'+ str(round(downarea,4)) + '%' +\n",
    "                '   MDT:' + str(drawdown_days)+\n",
    "                '   Date:' + str(data_1_new['eob'].iloc[e]) + ' - ' + str(data_1_new['eob'].iloc[s])] ,\n",
    "\n",
    "                loc='upper left',fontsize = 11)\n",
    "    \n",
    "    plt.plot(data_1_new['eob'], data_1_new['down'], color='#ec700a')\n",
    "    plt.fill_between(data_1_new['eob'], data_1_new['down'], 0, where=(data_1_new['down']<0), facecolor='#FF0000', alpha=0.1)\n",
    "    plt.xticks(range(0,data_1_size,int(data_1_size/m_size)))\n",
    "\n",
    "    fig.autofmt_xdate()\n",
    "    plt.grid(1)\n",
    "    plt.savefig(\"./temp/\" + str(j) + \"sy.jpg\")\n",
    "    plt.close()\n",
    "\n",
    "    fig=plt.figure(figsize=(20,10))  \n",
    "    plt.plot(data_1_new['eob'], data_1_new['high'])\n",
    "    plt.xticks(range(0,data_1_size,int(data_1_size/m_size)))\n",
    "    fig.autofmt_xdate()\n",
    "    plt.grid(1)\n",
    "    plt.savefig(\"./temp/\" + str(j) + \"p.jpg\")\n",
    "    plt.close()\n",
    "    \n",
    "    ##############################################################################################\n",
    "        \n",
    "    pp = metrics_df.loc[metrics_df['Metric'] == 'MSE', 'Mean'].values[0]\n",
    "    resP.append({\n",
    "        'MSE_no': j,\n",
    "        'min_MAE': pp\n",
    "    })\n",
    "    \n",
    "    rr = metrics_df.loc[metrics_df['Metric'] == 'RMSE', 'Mean'].values[0]\n",
    "    resR.append({\n",
    "        'RMSE_no': j,\n",
    "        'min_RMSE': rr\n",
    "    })\n",
    "    \n",
    "    ff = metrics_df.loc[metrics_df['Metric'] == 'R2', 'Mean'].values[0]\n",
    "    resF.append({\n",
    "        'R2_no': j,\n",
    "        'max_R2': ff\n",
    "    })\n",
    "    \n",
    "    ##############################################################################################\n",
    "\n",
    "    max_all = round(data_1_new['open'].iloc[-1]*100,2)\n",
    "    max_no = j\n",
    "\n",
    "    res1.append({\n",
    "        'All_no': max_no,\n",
    "        'max_All': max_all\n",
    "    })\n",
    "\n",
    "    max_CalmarY = round((data_1_new['open'].iloc[-1]/m_size*100*12)/(maxdrawdown*100),2)\n",
    "    \n",
    "    res2.append({\n",
    "        'CalmarY_no': max_no,\n",
    "        'max_CalmarY': max_CalmarY\n",
    "    })\n",
    "    \n",
    "    res3.append({\n",
    "        'Downarea_no': max_no,\n",
    "        'min_Downarea': downarea\n",
    "    })\n",
    "          \n",
    "    max_wp = round(wp_win_a/(wp_win_a + wp_lost_a)*100,2)\n",
    "    \n",
    "    res4.append({\n",
    "        'WP_no': max_no,\n",
    "        'max_WP': max_wp\n",
    "    })\n",
    "    \n",
    "    max_rrr = round(rrr_win/(rrr_win+abs(rrr_lost))*100,2)\n",
    "    \n",
    "    res5.append({\n",
    "        'RRR_no': max_no,\n",
    "        'max_RRR': max_rrr\n",
    "    })\n",
    "    \n",
    "    res6.append({\n",
    "        'Sharpe_no': max_no,\n",
    "        'max_Sharpe': sharpe\n",
    "    })\n",
    "        \n",
    "    res7.append({\n",
    "        'Sortino_no': max_no,\n",
    "        'max_Sortino': sortino\n",
    "    })\n",
    "    \n",
    "\n",
    "   ##############################################################################################\n",
    "\n",
    "aaaP = pd.DataFrame(resP)\n",
    "aaaR = pd.DataFrame(resR)\n",
    "aaaF = pd.DataFrame(resF)\n",
    "\n",
    "bbbP = aaaP.sort_values(by=\"min_MAE\",ascending=True)     ### 由小到大排序\n",
    "bbbR = aaaR.sort_values(by=\"min_RMSE\",ascending=True)    ### 由小到大排序\n",
    "bbbF = aaaF.sort_values(by=\"max_R2\",ascending=False)     ### 由大到小排序\n",
    "\n",
    "bbbP = bbbP.reset_index(drop=True)\n",
    "bbbR = bbbR.reset_index(drop=True)\n",
    "bbbF = bbbF.reset_index(drop=True)\n",
    "\n",
    "bbbP['RMSE_no'] = bbbR['RMSE_no']\n",
    "bbbP['min_RMSE'] = bbbR['min_RMSE']\n",
    "bbbP['R2_no'] = bbbF['R2_no']\n",
    "bbbP['max_R2'] = bbbF['max_R2']\n",
    "\n",
    "bbbP.to_csv(\"./temp/Best_2.csv\",index = False)\n",
    "\n",
    "   ##############################################################################################\n",
    "\n",
    "aaa1 = pd.DataFrame(res1)\n",
    "aaa2 = pd.DataFrame(res2)\n",
    "aaa3 = pd.DataFrame(res3)\n",
    "aaa4 = pd.DataFrame(res4)\n",
    "aaa5 = pd.DataFrame(res5)\n",
    "aaa6 = pd.DataFrame(res6)\n",
    "aaa7 = pd.DataFrame(res7)\n",
    "\n",
    "bbb1 = aaa1.sort_values(by=\"max_All\",ascending=False)       ### 由大到小排序\n",
    "bbb2 = aaa2.sort_values(by=\"max_CalmarY\",ascending=False)    \n",
    "bbb3 = aaa3.sort_values(by=\"min_Downarea\",ascending=False)     \n",
    "bbb4 = aaa4.sort_values(by=\"max_WP\",ascending=False)    \n",
    "bbb5 = aaa5.sort_values(by=\"max_RRR\",ascending=False)    \n",
    "bbb6 = aaa6.sort_values(by=\"max_Sharpe\",ascending=False)    \n",
    "bbb7 = aaa7.sort_values(by=\"max_Sortino\",ascending=False)   \n",
    "\n",
    "bbb1 = bbb1.reset_index(drop=True)\n",
    "bbb2 = bbb2.reset_index(drop=True)\n",
    "bbb3 = bbb3.reset_index(drop=True)\n",
    "bbb4 = bbb4.reset_index(drop=True)\n",
    "bbb5 = bbb5.reset_index(drop=True)\n",
    "bbb6 = bbb6.reset_index(drop=True)\n",
    "bbb7 = bbb7.reset_index(drop=True)\n",
    "\n",
    "bbb1['CalmarY_no'] = bbb2['CalmarY_no']\n",
    "bbb1['max_CalmarY'] = bbb2['max_CalmarY']\n",
    "bbb1['Downarea_no'] = bbb3['Downarea_no']\n",
    "bbb1['min_Downarea'] = bbb3['min_Downarea']\n",
    "bbb1['WP_no'] = bbb4['WP_no']\n",
    "bbb1['max_WP'] = bbb4['max_WP']\n",
    "bbb1['RRR_no'] = bbb5['RRR_no']\n",
    "bbb1['max_RRR'] = bbb5['max_RRR']\n",
    "bbb1['Sharpe_no'] = bbb6['Sharpe_no']\n",
    "bbb1['max_Sharpe'] = bbb6['max_Sharpe']\n",
    "bbb1['Sortino_no'] = bbb7['Sortino_no']\n",
    "bbb1['max_Sortino'] = bbb7['max_Sortino']\n",
    "\n",
    "bbb1.to_csv(\"./temp/Best_1.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a312579",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "New_World_2",
   "language": "python",
   "name": "new_world_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
