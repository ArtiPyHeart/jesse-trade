{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "400f7646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict, KFold, TimeSeriesSplit\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "\n",
    "\n",
    "USE_STANDARDIZATION = 0       #####  1 做标准化，0 不做标准化\n",
    "CV_TYPE = 2       ##### 交叉验证 1 KFold，2 时间顺序\n",
    "FOLD_NUM = 5      ##### 折数\n",
    "\n",
    "dataset_s = pd.read_csv('./test/RB99_1m_Turnover_31000_12120_1213.csv_tz80_Train_10877_ab.csv')    ####### 训练集文件\n",
    "dataset = dataset_s\n",
    "\n",
    "num_xunlian = len(dataset_s)\n",
    "data_1_size = 1213    ###### 测试数据行数  ###############\n",
    "m_size = 25     ####### 测试多少个月 #######\n",
    "buy = 1     ##### 多 ###################\n",
    "sell = 0     ##### 空 ####################\n",
    "rrr = 0.25     ###### 系数 ###################\n",
    "m = 1000       ###### 总资金 ###################\n",
    "\n",
    "### 模型训练指标保存\n",
    "res1 = []\n",
    "res2 = []\n",
    "res3 = []\n",
    "res4 = []\n",
    "res5 = []\n",
    "res6 = []\n",
    "res7 = []\n",
    "resP_A = []\n",
    "resP_B = []\n",
    "resR_A = []\n",
    "resR_B = []\n",
    "resF_A = []\n",
    "resF_B = []\n",
    "\n",
    "\n",
    "for j in range(1, 21):    ########## 从n维训练到多少维\n",
    "    num = j\n",
    "    \n",
    "    X = dataset.drop(['A0', 'B0'], axis=1)\n",
    "    y = dataset[['A0', 'B0']]\n",
    "    \n",
    "    ### 是否标准化\n",
    "    if USE_STANDARDIZATION == 1:\n",
    "        scaler = StandardScaler()\n",
    "        X_processed = scaler.fit_transform(X)\n",
    "    else:\n",
    "        scaler = None\n",
    "        X_processed = X.copy()\n",
    "    \n",
    "    ### PCA降维\n",
    "    pca = PCA(n_components=num, random_state=369)\n",
    "    X_pca = pca.fit_transform(X_processed)\n",
    "    \n",
    "    ### XGBoost模型多标签回归\n",
    "    base_model = xgb.XGBRegressor(random_state=369)\n",
    "    model = MultiOutputRegressor(base_model)\n",
    "    \n",
    "    ### 定义参数网格进行调优\n",
    "    param_grid = {\n",
    "        'estimator__n_estimators': [100, 200],\n",
    "        'estimator__learning_rate': [0.01, 0.1],\n",
    "        'estimator__max_depth': [3, 5]\n",
    "    }\n",
    "    \n",
    "    ### 交叉验证\n",
    "    if CV_TYPE == 1:\n",
    "        cv = KFold(n_splits=FOLD_NUM, shuffle=True, random_state=369)\n",
    "    else:\n",
    "        cv = TimeSeriesSplit(n_splits=FOLD_NUM)\n",
    "    \n",
    "    ### 网格搜索\n",
    "    grid_search = GridSearchCV(\n",
    "        model, \n",
    "        param_grid, \n",
    "        cv=cv, \n",
    "        scoring='neg_root_mean_squared_error', \n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_search.fit(X_pca, y)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    ### 交叉验证\n",
    "    if CV_TYPE == 1:\n",
    "        ### KFold可用cross_val_predict\n",
    "        cv_preds = cross_val_predict(best_model, X_pca, y, cv=cv)\n",
    "    else:\n",
    "        ####  时间顺序\n",
    "        cv_preds = np.zeros_like(y.values)  \n",
    "        seen_indices = set()  \n",
    "        \n",
    "        for train_idx, test_idx in cv.split(X_pca):\n",
    "            new_test_idx = [idx for idx in test_idx if idx not in seen_indices]\n",
    "            if not new_test_idx:\n",
    "                continue\n",
    "            \n",
    "            best_model.fit(X_pca[train_idx], y.iloc[train_idx])\n",
    "            preds = best_model.predict(X_pca[new_test_idx])\n",
    "            \n",
    "            ####  保存结果\n",
    "            cv_preds[new_test_idx] = preds\n",
    "            seen_indices.update(new_test_idx)\n",
    "    \n",
    "    ##### 计算A0和B0的指标\n",
    "    cv_mse_A = mean_squared_error(y['A0'], cv_preds[:, 0])\n",
    "    cv_rmse_A = np.sqrt(cv_mse_A)\n",
    "    cv_r2_A = r2_score(y['A0'], cv_preds[:, 0])\n",
    "    \n",
    "    cv_mse_B = mean_squared_error(y['B0'], cv_preds[:, 1])\n",
    "    cv_rmse_B = np.sqrt(cv_mse_B)\n",
    "    cv_r2_B = r2_score(y['B0'], cv_preds[:, 1])\n",
    "    \n",
    "    ### 保存指标\n",
    "    metrics_df_A = pd.DataFrame({\n",
    "        'Metric': ['MSE', 'RMSE', 'R2'],\n",
    "        'Mean': [cv_mse_A, cv_rmse_A, cv_r2_A],\n",
    "        'Std': [0, 0, 0]\n",
    "    })\n",
    "    metrics_df_B = pd.DataFrame({\n",
    "        'Metric': ['MSE', 'RMSE', 'R2'],\n",
    "        'Mean': [cv_mse_B, cv_rmse_B, cv_r2_B],\n",
    "        'Std': [0, 0, 0]\n",
    "    })\n",
    "    metrics_df_A.to_csv(f'./temp/{j}_A_r.csv', index=False)\n",
    "    metrics_df_B.to_csv(f'./temp/{j}_B_r.csv', index=False)\n",
    "    \n",
    "    #### 保存模型\n",
    "    pipeline = {\n",
    "        'use_standardization': USE_STANDARDIZATION,\n",
    "        'scaler': scaler,\n",
    "        'pca': pca,\n",
    "        'model': best_model,\n",
    "        'cv_type': CV_TYPE,\n",
    "        'fold_num': FOLD_NUM\n",
    "    }\n",
    "    joblib.dump(pipeline, f'./temp/{num}_x.pkl')\n",
    "    \n",
    "    ### 加载测试数据\n",
    "    data = pd.read_csv('./test/RB99_1m_Turnover_31000_12120_1213.csv_tz80_Test_1213_PCA.csv')     ###### 测试集数据\n",
    "    pipeline = joblib.load(f'./temp/{num}_x.pkl')\n",
    "    use_std = pipeline['use_standardization']\n",
    "    scaler = pipeline['scaler']\n",
    "    pca = pipeline['pca']\n",
    "    model = pipeline['model']\n",
    "    \n",
    "    X_test = data.drop(['A0', 'B0'], axis=1) if 'A0' in data.columns else data.drop(['B0'], axis=1, errors='ignore')\n",
    "    if use_std == 1:\n",
    "        X_test_processed = scaler.transform(X_test)\n",
    "    else:\n",
    "        X_test_processed = X_test.copy()\n",
    "    \n",
    "    X_test_pca = pca.transform(X_test_processed)\n",
    "    preds = model.predict(X_test_pca)\n",
    "    \n",
    "    ### 归一化确保 A0+B0=1\n",
    "    preds_sum = preds.sum(axis=1, keepdims=True)\n",
    "    preds = preds / preds_sum\n",
    "    A0_preds = preds[:, 0]\n",
    "    B0_preds = preds[:, 1]\n",
    "    \n",
    "    ### 保存推理结果\n",
    "    data['A0_pred'] = A0_preds\n",
    "    data['B0_pred'] = B0_preds\n",
    "    A0_n_preds = data['A0_pred'][num_xunlian : num_xunlian + data_1_size].reset_index(drop=True)\n",
    "    B0_n_preds = data['B0_pred'][num_xunlian : num_xunlian + data_1_size].reset_index(drop=True)\n",
    "    \n",
    "    with open(f'./temp/{num}_A.txt', 'a') as f:\n",
    "        for val in A0_n_preds:\n",
    "            f.write(f'{val}\\n')\n",
    "    with open(f'./temp/{num}_B.txt', 'a') as f:\n",
    "        for val in B0_n_preds:\n",
    "            f.write(f'{val}\\n')\n",
    "    \n",
    "    #### 信号处理\n",
    "    file_name = './temp/Show.csv'\n",
    "    df = pd.read_csv(file_name)\n",
    "    path_A = f'./temp/{j}_A.txt'\n",
    "    df_A = pd.read_csv(path_A, header=None, names=['A0_pred'])\n",
    "    path_B = f'./temp/{j}_B.txt'\n",
    "    df_B = pd.read_csv(path_B, header=None, names=['B0_pred'])\n",
    "    df['A0_pred'] = df_A['A0_pred']\n",
    "    df['B0_pred'] = df_B['B0_pred']\n",
    "    df['low'] = np.where(df['A0_pred'] > df['B0_pred'], 1, 0)\n",
    "    df.to_csv(f'./temp/{j}_x.csv', index=False)\n",
    "    \n",
    "    ### 可加入过滤信号逻辑(可选)  ###########################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    file_name = f'./temp/{j}_x.csv'\n",
    "    data_1_new = pd.read_csv(file_name)\n",
    "    \n",
    "    if buy == 0:\n",
    "        for i in range(0, data_1_size):\n",
    "            if data_1_new.loc[i, 'low'] == 1:\n",
    "                data_1_new.loc[i, 'volume'] = data_1_new.loc[i, 'volume'] * -1\n",
    "    else:\n",
    "        for i in range(0, data_1_size):\n",
    "            if data_1_new.loc[i, 'low'] == 0:\n",
    "                data_1_new.loc[i, 'volume'] = data_1_new.loc[i, 'volume'] * -1\n",
    "            if data_1_new.loc[i, 'low'] == 2:    ###### 过滤信号，2为不持仓\n",
    "                data_1_new.loc[i, 'volume'] = 0\n",
    "    \n",
    "    data_1_new['high'] = data_1_new['volume'].cumsum()\n",
    "    data_1_new['open'] = rrr * data_1_new['high'] / m\n",
    "    \n",
    "    ######################################################################################################\n",
    "\n",
    "    ### 胜率\n",
    "    wp_win = data_1_new['volume'] > 0\n",
    "    wp_lost = data_1_new['volume'] < 0\n",
    "    wp_nothing = data_1_new['volume'] == 0\n",
    "\n",
    "    wp_win_a = wp_win.sum()            \n",
    "    wp_lost_a = wp_lost.sum()\n",
    "    wp_nothing_a = wp_nothing.sum()\n",
    "\n",
    "    ### 盈亏比\n",
    "    rrr_win = data_1_new.loc[wp_win, 'volume'].sum()\n",
    "    rrr_lost = data_1_new.loc[wp_lost, 'volume'].sum()\n",
    "\n",
    "    ##############################################################################################\n",
    "    ###### 计算回撤数据\n",
    "    data_1_new['cum_max_open'] = data_1_new['open'].cummax()  \n",
    "    data_1_new['down'] = data_1_new['open'] - data_1_new['cum_max_open']  \n",
    "    data_1_new['down'] = data_1_new['down'].clip(upper=0)  \n",
    "\n",
    "    ##############################################################################################\n",
    "    ###### 计算回撤面积\n",
    "    downarea = data_1_new['down'].sum()\n",
    "\n",
    "    ##############################################################################################\n",
    "    ### 二级模型预留\n",
    "    \n",
    "\n",
    "    data_1_new['re'] = data_1_new['close'].pct_change() * 100\n",
    "    data_1_new['real'] = (data_1_new['close'] >= data_1_new['close'].shift(1)).astype(int)\n",
    "    data_1_new.loc[0, 'real'] = 0 \n",
    "\n",
    "    if buy == 0:\n",
    "        data_1_new['real_lab'] = np.where(\n",
    "            data_1_new['low'] != data_1_new['real'], \n",
    "            'G', 'N'\n",
    "        )\n",
    "    else:\n",
    "        data_1_new['real_lab'] = np.where(\n",
    "            data_1_new['low'] == data_1_new['real'], \n",
    "            'G', 'N'\n",
    "        )\n",
    "\n",
    "    data_1_new.loc[0, 'real_lab'] = 'G' \n",
    "\n",
    "    file_name = './temp/Show.csv'\n",
    "    df = pd.read_csv(file_name)        \n",
    "    data_1_new['show'] = df['low']\n",
    "\n",
    "    data_1_new['show_lab'] = np.where(\n",
    "        data_1_new['low'] == data_1_new['show'], \n",
    "        'G', 'N'\n",
    "    )\n",
    "\n",
    "    data_1_new.loc[0, 'show_lab'] = 'G'  \n",
    "\n",
    "    ##############################################################################################\n",
    "\n",
    "\n",
    "    if sell == 0:\n",
    "        data_1_new['re_real'] = np.where(\n",
    "            data_1_new['low'] == 0, \n",
    "            -data_1_new['re'], \n",
    "            data_1_new['re']\n",
    "        )\n",
    "    else:\n",
    "        data_1_new['re_real'] = np.where(\n",
    "            data_1_new['low'] == 1, \n",
    "            -data_1_new['re'], \n",
    "            data_1_new['re']\n",
    "        )\n",
    "\n",
    "    data_1_new.loc[0, 're_real'] = 0  \n",
    "\n",
    "    ##############################################################################################\n",
    "\n",
    "    ###### 计算夏普比率和索提诺比率\n",
    "    re_real = data_1_new['re_real'][1:]  \n",
    "    mean_re = re_real.mean()\n",
    "    std_re = re_real.std()\n",
    "    sharpe = round(mean_re / std_re * 100 if std_re != 0 else 0, 4)\n",
    "\n",
    "    neg_re = re_real[re_real < 0]\n",
    "    std_neg_re = neg_re.std() if not neg_re.empty else 0\n",
    "    sortino = round(mean_re / std_neg_re * 100 if std_neg_re != 0 else 0, 4)\n",
    "\n",
    "    ##############################################################################################\n",
    "\n",
    "    data_1_new.to_csv('./temp/' + str(j) + 'x.csv', index=False)\n",
    "\n",
    "    ###### 计算最大回撤\n",
    "    cum_max_open = data_1_new['open'].cummax()  ###### 累计最大值\n",
    "    drawdown = cum_max_open - data_1_new['open']  ###### 回撤值\n",
    "    s = np.argmax(drawdown)  ###### 最大回撤结束位置\n",
    "\n",
    "    ###### 确定最大回撤开始位置\n",
    "    if s == 0:\n",
    "        e = 0\n",
    "    else:\n",
    "        e = np.argmax(data_1_new['open'].iloc[:s]) \n",
    "\n",
    "    maxdrawdown = data_1_new['open'].iloc[e] - data_1_new['open'].iloc[s]  ###### 最大回撤\n",
    "    drawdown_days = s - e  ###### 回撤持续周期数\n",
    "    \n",
    "    \n",
    "    start_DAY = data_1_new.index[s] ######开始回撤的日期\n",
    "    end_DAY = data_1_new.index[e] ######结束回撤的日期\n",
    "    start_net_value = data_1_new[data_1_new.index == start_DAY]['open'].values[0] ######开始回撤的净值\n",
    "    end_net_value = data_1_new[data_1_new.index == end_DAY]['open'].values[0] ######结束回撤的净值\n",
    "    fig=plt.figure(figsize=(20,11))  \n",
    "    plt.plot(data_1_new['eob'], data_1_new['open'])\n",
    "    plt.plot([start_DAY, end_DAY], [start_net_value, end_net_value], linestyle='--', color='r')\n",
    "\n",
    "    plt.xticks(range(0,data_1_size,int(data_1_size/m_size))) \n",
    "    \n",
    "    plt.legend(['All:' + str(round(data_1_new['open'].iloc[-1]*100,2)) + '%' +\n",
    "                '   ' + str(m_size) + 'm'\n",
    "                '   Year:'+ str(round(data_1_new['open'].iloc[-1]/m_size*100*12,2)) + '%' +\n",
    "                '   CalmarY:'+ str(round((data_1_new['open'].iloc[-1]/m_size*100*12)/(maxdrawdown*100),2)) +\n",
    "                '   WP:' + str(round(wp_win_a/(wp_win_a + wp_lost_a)*100,2)) + '%' +\n",
    "                '   RRR:' + str(round(rrr_win/(rrr_win+abs(rrr_lost))*100,2)) + '%' + ' / ' + str(round(rrr_win/abs(rrr_lost),2)) +\n",
    "                '   T/N:' + str(wp_win_a + wp_lost_a ) + ' / ' + str(wp_nothing_a) +\n",
    "                '   Sharpe:' + str(sharpe) +\n",
    "                '   Sortino:' + str(sortino) +\n",
    "                '   A0_MSE:' + str(round(cv_mse_A, 4)) +\n",
    "                '   B0_MSE:' + str(round(cv_mse_B, 4)),\n",
    "                'MD:'+ str(round(maxdrawdown*100,2)) + '%' +\n",
    "                '   DA:'+ str(round(downarea,4)) + '%' +\n",
    "                '   MDT:' + str(drawdown_days)+\n",
    "                '   Date:' + str(data_1_new['eob'].iloc[e]) + ' - ' + str(data_1_new['eob'].iloc[s])] ,\n",
    "                loc='upper left',fontsize = 11)\n",
    "    plt.plot(data_1_new['eob'], data_1_new['down'], color='#ec700a')\n",
    "    plt.fill_between(data_1_new['eob'], data_1_new['down'], 0, where=(data_1_new['down']<0), facecolor='#FF0000', alpha=0.1)\n",
    "    plt.xticks(range(0,data_1_size,int(data_1_size/m_size)))\n",
    "    fig.autofmt_xdate()\n",
    "    plt.grid(1)\n",
    "    plt.savefig(f\"./temp/{j}sy.jpg\")\n",
    "    plt.close()\n",
    "\n",
    "    fig=plt.figure(figsize=(20,10))  \n",
    "    plt.plot(data_1_new['eob'], data_1_new['high'])\n",
    "    plt.xticks(range(0,data_1_size,int(data_1_size/m_size)))\n",
    "    fig.autofmt_xdate()\n",
    "    plt.grid(1)\n",
    "    plt.savefig(f\"./temp/{j}p.jpg\")\n",
    "    plt.close()\n",
    "    \n",
    "    ##############################################################################################\n",
    "    ### 保存双概率的评估结果\n",
    "    resP_A.append({'MSE_no': j, 'min_MSE_A': cv_mse_A})\n",
    "    resP_B.append({'MSE_no': j, 'min_MSE_B': cv_mse_B})\n",
    "    resR_A.append({'RMSE_no': j, 'min_RMSE_A': cv_rmse_A})\n",
    "    resR_B.append({'RMSE_no': j, 'min_RMSE_B': cv_rmse_B})\n",
    "    resF_A.append({'R2_no': j, 'max_R2_A': cv_r2_A})\n",
    "    resF_B.append({'R2_no': j, 'max_R2_B': cv_r2_B})\n",
    "    \n",
    "    ##############################################################################################\n",
    "\n",
    "    max_all = round(data_1_new['open'].iloc[-1]*100,2)\n",
    "    res1.append({'All_no': j, 'max_All': max_all})\n",
    "\n",
    "    max_CalmarY = round((data_1_new['open'].iloc[-1]/m_size*100*12)/(maxdrawdown*100),2)\n",
    "    res2.append({'CalmarY_no': j, 'max_CalmarY': max_CalmarY})\n",
    "\n",
    "    res3.append({'Downarea_no': j, 'min_Downarea': downarea})\n",
    "\n",
    "    max_wp = round(wp_win_a/(wp_win_a + wp_lost_a)*100,2)\n",
    "    res4.append({'WP_no': j, 'max_WP': max_wp})\n",
    "\n",
    "    max_rrr = round(rrr_win/(rrr_win+abs(rrr_lost))*100,2)\n",
    "    res5.append({'RRR_no': j, 'max_RRR': max_rrr})\n",
    "\n",
    "    res6.append({'Sharpe_no': j, 'max_Sharpe': sharpe})\n",
    "    res7.append({'Sortino_no': j, 'max_Sortino': sortino})\n",
    "\n",
    "\n",
    "\n",
    "### A0的指标\n",
    "aaaP_A = pd.DataFrame(resP_A)\n",
    "aaaR_A = pd.DataFrame(resR_A)\n",
    "aaaF_A = pd.DataFrame(resF_A)\n",
    "bbbP_A = aaaP_A.sort_values(by=\"min_MSE_A\",ascending=True).reset_index(drop=True)\n",
    "bbbR_A = aaaR_A.sort_values(by=\"min_RMSE_A\",ascending=True).reset_index(drop=True)\n",
    "bbbF_A = aaaF_A.sort_values(by=\"max_R2_A\",ascending=False).reset_index(drop=True)\n",
    "bbbP_A['RMSE_no'] = bbbR_A['RMSE_no']\n",
    "bbbP_A['min_RMSE_A'] = bbbR_A['min_RMSE_A']\n",
    "bbbP_A['R2_no'] = bbbF_A['R2_no']\n",
    "bbbP_A['max_R2_A'] = bbbF_A['max_R2_A']\n",
    "bbbP_A.to_csv(\"./temp/Best_A.csv\",index=False)\n",
    "\n",
    "### B0的指标\n",
    "aaaP_B = pd.DataFrame(resP_B)\n",
    "aaaR_B = pd.DataFrame(resR_B)\n",
    "aaaF_B = pd.DataFrame(resF_B)\n",
    "bbbP_B = aaaP_B.sort_values(by=\"min_MSE_B\",ascending=True).reset_index(drop=True)\n",
    "bbbR_B = aaaR_B.sort_values(by=\"min_RMSE_B\",ascending=True).reset_index(drop=True)\n",
    "bbbF_B = aaaF_B.sort_values(by=\"max_R2_B\",ascending=False).reset_index(drop=True)\n",
    "bbbP_B['RMSE_no'] = bbbR_B['RMSE_no']\n",
    "bbbP_B['min_RMSE_B'] = bbbR_B['min_RMSE_B']\n",
    "bbbP_B['R2_no'] = bbbF_B['R2_no']\n",
    "bbbP_B['max_R2_B'] = bbbF_B['max_R2_B']\n",
    "bbbP_B.to_csv(\"./temp/Best_B.csv\",index=False)\n",
    "\n",
    "\n",
    "aaa1 = pd.DataFrame(res1)\n",
    "aaa2 = pd.DataFrame(res2)\n",
    "aaa3 = pd.DataFrame(res3)\n",
    "aaa4 = pd.DataFrame(res4)\n",
    "aaa5 = pd.DataFrame(res5)\n",
    "aaa6 = pd.DataFrame(res6)\n",
    "aaa7 = pd.DataFrame(res7)\n",
    "\n",
    "bbb1 = aaa1.sort_values(by=\"max_All\",ascending=False).reset_index(drop=True)\n",
    "bbb2 = aaa2.sort_values(by=\"max_CalmarY\",ascending=False).reset_index(drop=True)\n",
    "bbb3 = aaa3.sort_values(by=\"min_Downarea\",ascending=False).reset_index(drop=True)\n",
    "bbb4 = aaa4.sort_values(by=\"max_WP\",ascending=False).reset_index(drop=True)\n",
    "bbb5 = aaa5.sort_values(by=\"max_RRR\",ascending=False).reset_index(drop=True)\n",
    "bbb6 = aaa6.sort_values(by=\"max_Sharpe\",ascending=False).reset_index(drop=True)\n",
    "bbb7 = aaa7.sort_values(by=\"max_Sortino\",ascending=False).reset_index(drop=True)\n",
    "\n",
    "bbb1['CalmarY_no'] = bbb2['CalmarY_no']\n",
    "bbb1['max_CalmarY'] = bbb2['max_CalmarY']\n",
    "bbb1['Downarea_no'] = bbb3['Downarea_no']\n",
    "bbb1['min_Downarea'] = bbb3['min_Downarea']\n",
    "bbb1['WP_no'] = bbb4['WP_no']\n",
    "bbb1['max_WP'] = bbb4['max_WP']\n",
    "bbb1['RRR_no'] = bbb5['RRR_no']\n",
    "bbb1['max_RRR'] = bbb5['max_RRR']\n",
    "bbb1['Sharpe_no'] = bbb6['Sharpe_no']\n",
    "bbb1['max_Sharpe'] = bbb6['max_Sharpe']\n",
    "bbb1['Sortino_no'] = bbb7['Sortino_no']\n",
    "bbb1['max_Sortino'] = bbb7['max_Sortino']\n",
    "\n",
    "bbb1.to_csv(\"./temp/Best_1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb47182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025768a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957531dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "New_World_2",
   "language": "python",
   "name": "new_world_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
