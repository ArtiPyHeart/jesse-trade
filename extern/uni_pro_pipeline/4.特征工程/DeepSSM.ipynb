{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaa3f5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备：cpu\n",
      "数据加载完成：1457行，77维特征，批次形状：torch.Size([1, 1457, 77])\n",
      "开始训练DeepSSM模型...\n",
      "Epoch 10/50 | Loss: 119.6039\n",
      "Epoch 20/50 | Loss: 119.5120\n",
      "早停触发：第23轮损失未改善，停止训练\n",
      "特征生成完成，形状：torch.Size([1457, 5])（1457行，5维）\n",
      "特征已保存到 deep_ssm_features.csv\n",
      "模型已保存到 deep_ssm_model.pt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "##### 加载数据\n",
    "\n",
    "def load_data(csv_path, device):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    features = df.values\n",
    "    #### 如果是差分处理过的数据可以不用做标准化\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "    return torch.tensor(features_scaled, dtype=torch.float32, device=device), scaler\n",
    "\n",
    "\n",
    "##### SSM模型\n",
    "\n",
    "class DeepSSM(nn.Module):\n",
    "    \n",
    "    ### 结合LSTM数据的时间依赖，用参数化状态转移和观测模型来实现数据的状态推断\n",
    "    \n",
    "    def __init__(self, obs_dim, state_dim=5, lstm_hidden=64):    \n",
    "        \n",
    "        super().__init__()\n",
    "        self.obs_dim = obs_dim    ######  观测数据的维度，（原始数据）\n",
    "        self.state_dim = state_dim   #####  潜在状态的维度，即输出状态特征的维度\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=obs_dim,\n",
    "            hidden_size=lstm_hidden,     ####LSTM隐藏层的维度，用于提取序列特征\n",
    "            batch_first=True,\n",
    "            num_layers=1    ####### 单层 LSTM\n",
    "        )\n",
    "        self.transition = nn.Sequential(\n",
    "            nn.Linear(lstm_hidden + state_dim, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 2 * state_dim)\n",
    "        )\n",
    "        self.observation = nn.Sequential(\n",
    "            nn.Linear(state_dim, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 2 * obs_dim)\n",
    "        )\n",
    "        self.initial_state_mean = nn.Parameter(torch.zeros(state_dim))\n",
    "        self.initial_state_log_var = nn.Parameter(torch.zeros(state_dim))\n",
    "\n",
    "        \n",
    "  #### 计算状态转移分布的参数（均值和对数方差）\n",
    "\n",
    "    def get_transition_dist(self, lstm_out, z_prev):\n",
    "        input_ = torch.cat([lstm_out, z_prev], dim=-1)\n",
    "        out = self.transition(input_)\n",
    "        mean, log_var = torch.split(out, out.size(-1) // 2, dim=-1)\n",
    "        return mean, torch.clamp(log_var, -10, 10)\n",
    "\n",
    "    \n",
    "#### 计算观测分布的参数（均值和对数方差）\n",
    "\n",
    "    def get_observation_dist(self, z):\n",
    "        out = self.observation(z)\n",
    "        mean, log_var = torch.split(out, out.size(-1) // 2, dim=-1)\n",
    "        return mean, torch.clamp(log_var, -10, 10)\n",
    "\n",
    "\n",
    "###### 数值法计算雅可比矩阵,用于扩展卡尔曼的线性化\n",
    "\n",
    "def compute_jacobian_numerical(f, x, eps=1e-6):\n",
    "    x = x.detach().clone()\n",
    "    y = f(x)\n",
    "    obs_dim = y.shape[1]\n",
    "    state_dim = x.shape[1]\n",
    "    jac = torch.zeros(obs_dim, state_dim, device=x.device)\n",
    "    for i in range(state_dim):\n",
    "        x_eps = x.clone()\n",
    "        x_eps[0, i] += eps\n",
    "        y_eps = f(x_eps)\n",
    "        jac[:, i] = (y_eps - y).squeeze(0) / eps\n",
    "    return jac\n",
    "\n",
    "\n",
    "##### 嵌入LSTM的概率模型定义\n",
    "\n",
    "def deep_ssm_model(y, model):\n",
    "    \n",
    "    ###### 基于Pyro概率模型定义状态空间模型的生成过程，（先验和观测模型）    \n",
    "    #####  从初始状态按时间步转移状态，再由状态生成观测数据\n",
    "    \n",
    "    batch_size, T, obs_dim = y.shape\n",
    "    state_dim = model.state_dim\n",
    "    \n",
    "    ###### 用LSTM提取整个观测序列的特征\n",
    "    lstm_out, _ = model.lstm(y)\n",
    "    \n",
    "    #####初始状态的先验分布\n",
    "    z0_mean = model.initial_state_mean.expand(batch_size, -1)\n",
    "    z0_log_var = model.initial_state_log_var.expand(batch_size, -1)\n",
    "    z = pyro.sample(\"z0\", dist.Normal(z0_mean, torch.exp(0.5 * z0_log_var)).to_event(1))\n",
    "    \n",
    "    ### 按时间步迭代，定义状态转移和观测过程\n",
    "    for t in range(1, T):\n",
    "        transition_mean, transition_log_var = model.get_transition_dist(lstm_out[:, t, :], z)\n",
    "        z = pyro.sample(f\"z{t}\", dist.Normal(transition_mean, torch.exp(0.5 * transition_log_var)).to_event(1))\n",
    "        obs_mean, obs_log_var = model.get_observation_dist(z)\n",
    "        pyro.sample(f\"y{t}\", dist.Normal(obs_mean, torch.exp(0.5 * obs_log_var)).to_event(1), obs=y[:, t, :])\n",
    "\n",
    "def deep_ssm_guide(y, model):\n",
    "    \n",
    "    ###### 定义变分分布（近似后验分布）用于变分推断\n",
    "    ####### 为了计算和优化，所以会用参数化的分布近似状态的后验分布\n",
    "    \n",
    "    batch_size, T, obs_dim = y.shape\n",
    "    state_dim = model.state_dim\n",
    "    \n",
    "    ###### 定义状态后验的均值（z_loc）和标准差（z_scale）参数\n",
    "    \n",
    "    z_loc = pyro.param(\"z_loc\", torch.zeros(batch_size, T, state_dim, device=y.device))\n",
    "    z_scale = pyro.param(\"z_scale\", torch.ones(batch_size, T, state_dim, device=y.device) * 0.1, \n",
    "                        constraint=dist.constraints.positive)\n",
    "    \n",
    "    ###### 按时间步定义每个状态zt的变分分布\n",
    "    \n",
    "    for t in range(T):\n",
    "        pyro.sample(f\"z{t}\", dist.Normal(z_loc[:, t, :], z_scale[:, t, :]).to_event(1))\n",
    "\n",
    "\n",
    "######### 使用扩展卡尔曼滤波\n",
    "#######  在已知观测序列的情况下递归估计潜在状态\n",
    "\n",
    "def deep_ssm_kalman_filter(y_seq, model):\n",
    "    T = len(y_seq)\n",
    "    state_dim = model.state_dim\n",
    "    obs_dim = model.obs_dim\n",
    "    device = y_seq.device\n",
    "    \n",
    "    lstm_hidden = torch.zeros(1, 1, model.lstm.hidden_size, device=device)\n",
    "    lstm_cell = torch.zeros(1, 1, model.lstm.hidden_size, device=device)\n",
    "    z = model.initial_state_mean.unsqueeze(0).to(device)\n",
    "    P = torch.diag(torch.exp(model.initial_state_log_var)).to(device)\n",
    "    \n",
    "    states = [z.squeeze(0).cpu()]\n",
    "    \n",
    "    ### 按时间步进行\n",
    "    for t in range(1, T):\n",
    "        \n",
    "        ###### 用LSTM处理当前观测来获取特征\n",
    "        \n",
    "        y_t = y_seq[t].unsqueeze(0).unsqueeze(0)\n",
    "        lstm_out, (lstm_hidden, lstm_cell) = model.lstm(y_t, (lstm_hidden, lstm_cell))\n",
    "        lstm_out = lstm_out.squeeze(0)\n",
    "        \n",
    "        #### 基于前一个状态和LSTM特征来计算当前状态的先验分布\n",
    "        \n",
    "        transition_mean, transition_log_var = model.get_transition_dist(lstm_out, z)\n",
    "        z_pred = transition_mean\n",
    "        transition_var = torch.diag(torch.exp(transition_log_var.squeeze(0)))\n",
    "        P_pred = transition_var.to(device)\n",
    "        \n",
    "        y_t_obs = y_seq[t].unsqueeze(0)\n",
    "        obs_mean, obs_log_var = model.get_observation_dist(z_pred)\n",
    "        \n",
    "        \n",
    "        ###### 定义观测函数（输入状态，输出观测均值）用于计算雅可比矩阵\n",
    "        \n",
    "        def observation_func(x):\n",
    "            return model.get_observation_dist(x)[0]\n",
    "        \n",
    "        ######  用数值计算观测函数在预测状态的雅可比矩阵\n",
    "        \n",
    "        H = compute_jacobian_numerical(observation_func, z_pred)\n",
    "        H = H[:obs_dim, :state_dim].to(device)\n",
    "        \n",
    "        #######  观测噪声协方差矩阵\n",
    "        \n",
    "        obs_var = torch.exp(obs_log_var.squeeze(0)).to(device)\n",
    "        R = torch.diag(obs_var) if len(obs_var) == obs_dim else torch.eye(obs_dim, device=device)*0.1\n",
    "        \n",
    "        \n",
    "        #### 计算卡尔曼增益，用于权衡预测和观测的可信度\n",
    "        \n",
    "        H_t = H.T\n",
    "        temp = H @ P_pred @ H_t + R\n",
    "        temp_inv = torch.inverse(temp + torch.eye(obs_dim, device=device)*1e-6)\n",
    "        K = P_pred @ H_t @ temp_inv\n",
    "        \n",
    "        \n",
    "        ##### 用观测残差更新状态\n",
    "        \n",
    "        error = (y_t_obs - obs_mean).T.to(device)\n",
    "        z = (z_pred.T + K @ error).T\n",
    "        P = (torch.eye(state_dim, device=device) - K @ H) @ P_pred\n",
    "        \n",
    "        states.append(z.squeeze(0).cpu())\n",
    "    \n",
    "    return torch.stack(states), P.cpu()\n",
    "\n",
    "\n",
    "##### 模型保存和加载\n",
    "\n",
    "def save_deep_model(model, scaler, path):\n",
    "    torch.save({\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"obs_dim\": model.obs_dim,\n",
    "        \"state_dim\": model.state_dim,\n",
    "        \"lstm_hidden\": model.lstm.hidden_size,\n",
    "        \"scaler\": scaler\n",
    "    }, path)\n",
    "    print(f\"模型已保存到 {path}\")\n",
    "\n",
    "def load_deep_model(path, device):\n",
    "    checkpoint = torch.load(path, map_location=device)\n",
    "    model = DeepSSM(\n",
    "        obs_dim=checkpoint[\"obs_dim\"],\n",
    "        state_dim=checkpoint[\"state_dim\"],\n",
    "        lstm_hidden=checkpoint[\"lstm_hidden\"]\n",
    "    ).to(device)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    return model, checkpoint[\"scaler\"]\n",
    "\n",
    "\n",
    "###### 参数配置\n",
    "\n",
    "def main():\n",
    "    config = {\n",
    "        \"csv_path\": \"./test.csv\", ######### 原始特征文件\n",
    "        \"model_path\": \"deep_ssm_model.pt\",   ######### 模型保存\n",
    "        \"feature_save_path\": \"deep_ssm_features.csv\",   ######### 特征保存\n",
    "        \"state_dim\": 5,    ######### 新特征数据维度数量\n",
    "        \"lstm_hidden\": 64,  ######### LSTM 隐藏层维度\n",
    "        \"max_epochs\": 50,  ###### 最大训练轮数\n",
    "        \"patience\": 5,        ###### 早停耐心值，5个epoch无改善则停止\n",
    "        \"min_delta\": 0.01,   ###### 损失改善的最小阈值\n",
    "        \"lr\": 0.001   ###### 学习率\n",
    "    }\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"使用设备：{device}\")\n",
    "    \n",
    "    ##### 加载数据\n",
    "    y_raw, scaler = load_data(config[\"csv_path\"], device)\n",
    "    T, obs_dim = y_raw.shape\n",
    "    y = y_raw.unsqueeze(0)\n",
    "    print(f\"数据加载完成：{T}行，{obs_dim}维特征，批次形状：{y.shape}\")\n",
    "    \n",
    "    ##### 初始化模型\n",
    "    model = DeepSSM(obs_dim=obs_dim, state_dim=config[\"state_dim\"], lstm_hidden=config[\"lstm_hidden\"]).to(device)\n",
    "    \n",
    "    ##### 训练模型\n",
    "    optimizer = pyro.optim.Adam({\"lr\": config[\"lr\"]})\n",
    "    svi = SVI(\n",
    "        model=lambda: deep_ssm_model(y, model),\n",
    "        guide=lambda: deep_ssm_guide(y, model),\n",
    "        optim=optimizer,\n",
    "        loss=Trace_ELBO()\n",
    "    )\n",
    "    print(\"开始训练DeepSSM模型...\")\n",
    "    \n",
    "    ##### 早停参数初始化\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(config[\"max_epochs\"]):\n",
    "        loss = svi.step()\n",
    "        avg_loss = loss / T  ##### 平均损失\n",
    "        \n",
    "        ##### 打印每10个epoch的损失\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{config['max_epochs']} | Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        ##### 早停逻辑\n",
    "        if avg_loss < best_loss - config[\"min_delta\"]:\n",
    "            best_loss = avg_loss\n",
    "            patience_counter = 0  ##### 重置计数器\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            ##### 达到耐心值，停止训练\n",
    "            if patience_counter >= config[\"patience\"]:\n",
    "                print(f\"早停触发：第{epoch+1}轮损失未改善，停止训练\")\n",
    "                break\n",
    "    \n",
    "    ##### 生成特征\n",
    "    states, _ = deep_ssm_kalman_filter(y_raw, model)\n",
    "    print(f\"特征生成完成，形状：{states.shape}（{states.shape[0]}行，{states.shape[1]}维）\")\n",
    "    \n",
    "    ##### 保存特征\n",
    "    feature_df = pd.DataFrame(\n",
    "        states.detach().numpy(),\n",
    "        columns=[f\"deep_ssm_feature_{i}\" for i in range(config[\"state_dim\"])]\n",
    "    )\n",
    "    feature_df.to_csv(config[\"feature_save_path\"], index=False)\n",
    "    print(f\"特征已保存到 {config['feature_save_path']}\")\n",
    "    \n",
    "    ##### 保存模型\n",
    "    save_deep_model(model, scaler, config[\"model_path\"])\n",
    "    return states\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    states = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2508383",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### 实时特征输出 ###########\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#### 模型定义\n",
    "\n",
    "class DeepSSM(torch.nn.Module):\n",
    "    def __init__(self, obs_dim, state_dim=5, lstm_hidden=64):\n",
    "        super().__init__()\n",
    "        self.obs_dim = obs_dim\n",
    "        self.state_dim = state_dim\n",
    "        self.lstm = torch.nn.LSTM(obs_dim, lstm_hidden, batch_first=True, num_layers=1)\n",
    "        self.transition = torch.nn.Sequential(\n",
    "            torch.nn.Linear(lstm_hidden + state_dim, 128),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(128, 2 * state_dim)\n",
    "        )\n",
    "        self.observation = torch.nn.Sequential(\n",
    "            torch.nn.Linear(state_dim, 128),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(128, 2 * obs_dim)\n",
    "        )\n",
    "\n",
    "    def get_transition_dist(self, lstm_out, z_prev):\n",
    "        input_ = torch.cat([lstm_out, z_prev], dim=-1)\n",
    "        out = self.transition(input_)\n",
    "        mean, log_var = torch.split(out, out.size(-1) // 2, dim=-1)\n",
    "        return mean, torch.clamp(log_var, -10, 10)\n",
    "\n",
    "    def get_observation_dist(self, z):\n",
    "        out = self.observation(z)\n",
    "        mean, log_var = torch.split(out, out.size(-1) // 2, dim=-1)\n",
    "        return mean, torch.clamp(log_var, -10, 10)\n",
    "\n",
    "    \n",
    "\n",
    "######## 雅可比矩阵\n",
    "\n",
    "def compute_jacobian_numerical(f, x, eps=1e-6):\n",
    "\n",
    "    x = x.detach().clone()\n",
    "    y = f(x)\n",
    "    obs_dim, state_dim = y.shape[1], x.shape[1]\n",
    "    jac = torch.zeros(obs_dim, state_dim)\n",
    "    for i in range(state_dim):\n",
    "        x_eps = x.clone()\n",
    "        x_eps[0, i] += eps\n",
    "        jac[:, i] = (f(x_eps) - y).squeeze(0) / eps\n",
    "    return jac\n",
    "\n",
    "\n",
    "##### 实时特征生成\n",
    "class DeepSSMRealTime:\n",
    "    def __init__(self, model_path):\n",
    "        ##### 加载模型和标准化\n",
    "        checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "        self.scaler = checkpoint[\"scaler\"]\n",
    "        self.model = DeepSSM(\n",
    "            obs_dim=checkpoint[\"obs_dim\"],\n",
    "            state_dim=checkpoint[\"state_dim\"],\n",
    "            lstm_hidden=checkpoint[\"lstm_hidden\"]\n",
    "        )\n",
    "        self.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        self.model.eval()  ###### 评估模式\n",
    "        \n",
    "        ###### 初始化状态变量\n",
    "        self.state_dim = checkpoint[\"state_dim\"]\n",
    "        self.obs_dim = checkpoint[\"obs_dim\"]\n",
    "        self.z = torch.zeros(1, self.state_dim)  ###### 状态估计\n",
    "        self.P = torch.eye(self.state_dim) * 0.1  ###### 协方差矩阵\n",
    "        self.lstm_hidden = torch.zeros(1, 1, self.model.lstm.hidden_size)  ###### LSTM状态\n",
    "        self.lstm_cell = torch.zeros(1, 1, self.model.lstm.hidden_size)    ###### LSTM状态\n",
    "\n",
    "    def process(self, new_data):\n",
    "\n",
    "        ##### 标准化新数据\n",
    "        new_data_scaled = self.scaler.transform(new_data.reshape(1, -1))\n",
    "        new_data_tensor = torch.tensor(new_data_scaled, dtype=torch.float32)\n",
    "        \n",
    "        ##### LSTM单步更新\n",
    "        lstm_out, (self.lstm_hidden, self.lstm_cell) = self.model.lstm(\n",
    "            new_data_tensor.unsqueeze(0),  ###### 形状：[1,1,obs_dim]\n",
    "            (self.lstm_hidden, self.lstm_cell)\n",
    "        )\n",
    "        lstm_out = lstm_out.squeeze(0)  ###### 形状：[1, lstm_hidden]\n",
    "        \n",
    "        ##### 扩展卡尔曼滤波状态预测\n",
    "        with torch.no_grad():\n",
    "            trans_mean, trans_logvar = self.model.get_transition_dist(lstm_out, self.z)\n",
    "            z_pred = trans_mean  ##### 预测状态\n",
    "            trans_var = torch.diag(torch.exp(trans_logvar.squeeze(0)))\n",
    "            P_pred = trans_var  ##### 预测协方差\n",
    "        \n",
    "        #### 观测模型与雅可比矩阵\n",
    "        with torch.no_grad():\n",
    "            obs_mean, obs_logvar = self.model.get_observation_dist(z_pred)\n",
    "        \n",
    "        #### 计算雅可比矩阵\n",
    "        H = compute_jacobian_numerical(lambda x: self.model.get_observation_dist(x)[0], z_pred)\n",
    "        \n",
    "        #### 卡尔曼增益与状态更新\n",
    "        obs_var = torch.exp(obs_logvar.squeeze(0))\n",
    "        R = torch.diag(obs_var) if len(obs_var) == self.obs_dim else torch.eye(self.obs_dim) * 0.1\n",
    "        H_t = H.T\n",
    "        temp = H @ P_pred @ H_t + R + torch.eye(self.obs_dim) * 1e-6  ##### 数值稳定\n",
    "        K = P_pred @ H_t @ torch.inverse(temp)  #####卡尔曼增益\n",
    "        \n",
    "        #####更新状态和协方差\n",
    "        error = (new_data_tensor - obs_mean).T  ##### 残差\n",
    "        self.z = (z_pred.T + K @ error).T  ##### 新状态估计\n",
    "        self.P = (torch.eye(self.state_dim) - K @ H) @ P_pred  ##### 新协方差\n",
    "        \n",
    "        ##### 返回生成的特征\n",
    "        return self.z.detach().numpy().flatten()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    ##### 导入模型\n",
    "    realtime = DeepSSMRealTime(\"deep_ssm_model.pt\")\n",
    "    print(f\"实时特征生成器初始化完成（{realtime.obs_dim}维输入，{realtime.state_dim}维特征）\")\n",
    "    \n",
    "    ##### 要用实际数据源\n",
    "    for i in range(5):\n",
    "        ##### 生成模拟数据\n",
    "        new_data = np.random.randn(realtime.obs_dim)  \n",
    "        \n",
    "        ##### 生成特征\n",
    "        feature = realtime.process(new_data)\n",
    "        \n",
    "        ##### 实时推理需要结果给到下游模型\n",
    "        print(f\"第{i+1}条数据特征：{feature[:3].round(4)}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89edc39b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30c918e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4556ead9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "New_World_2",
   "language": "python",
   "name": "new_world_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
