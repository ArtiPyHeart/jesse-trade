import gc
import hashlib

import numpy as np
import pandas as pd
from pathlib import Path

from src.features.feature_selection.rfcq_selector import RFCQSelector
from src.models.deep_ssm import DeepSSMConfig, DeepSSM
from src.models.lgssm import LGSSMConfig, LGSSM
from .features import ALL_FEATS

FRAC_FEATS = [i for i in ALL_FEATS if i.startswith("frac_") and i.endswith("_diff")]
deep_ssm_config = DeepSSMConfig(
    obs_dim=len(FRAC_FEATS),
)
lg_ssm_config = LGSSMConfig(
    obs_dim=len(FRAC_FEATS),
)


class FeatureSelector:
    def __init__(self, model_save_dir: Path = None, load_existing: bool = False):
        self.model_save_dir = model_save_dir
        # ğŸ”§ æ·»åŠ ç¼“å­˜ï¼Œé¿å…é‡å¤è®¡ç®—å¤§å‹ DataFrame
        self._cached_all_features = None
        self._cached_train_x_hash = None  # ä½¿ç”¨å†…å®¹å“ˆå¸Œæ›¿ä»£ id()ï¼Œæ›´å¯é 

        if load_existing and model_save_dir:
            # å°è¯•åŠ è½½å·²æœ‰æ¨¡å‹
            deep_ssm_path = model_save_dir / "deep_ssm"
            lg_ssm_path = model_save_dir / "lg_ssm"

            if deep_ssm_path.with_suffix(".safetensors").exists():
                self.deep_ssm_model = DeepSSM.load(deep_ssm_path.resolve().as_posix())
            else:
                self.deep_ssm_model = DeepSSM(config=deep_ssm_config)

            if lg_ssm_path.with_suffix(".safetensors").exists():
                self.lg_ssm_model = LGSSM.load(lg_ssm_path.resolve().as_posix())
            else:
                self.lg_ssm_model = LGSSM(config=lg_ssm_config)
        else:
            self.deep_ssm_model = DeepSSM(config=deep_ssm_config)
            self.lg_ssm_model = LGSSM(config=lg_ssm_config)

    @property
    def selector(self):
        return RFCQSelector(verbose=True)

    def _compute_data_hash(self, df: pd.DataFrame) -> str:
        """åŸºäºå†…å®¹çš„å¿«é€Ÿå“ˆå¸Œï¼Œç”¨äºå¯é çš„ç¼“å­˜æ£€æµ‹"""
        # ä½¿ç”¨ shape + é¦–å°¾è¡Œ + é¦–ä¸ªç´¢å¼•å€¼è¿›è¡Œå¿«é€Ÿå“ˆå¸Œ
        shape_str = f"{df.shape}"
        first_row = df.iloc[0].values.tobytes() if len(df) > 0 else b""
        last_row = df.iloc[-1].values.tobytes() if len(df) > 0 else b""
        index_val = str(df.index[0]) if len(df) > 0 else "0"
        content = shape_str.encode() + first_row + last_row + index_val.encode()
        return hashlib.md5(content).hexdigest()

    def fit(self, train_x):
        if not self.deep_ssm_model.is_fitted:
            self.deep_ssm_model.fit(train_x[FRAC_FEATS])
            # ä¿å­˜ deep ssm æ¨¡å‹
            if self.model_save_dir:
                self.model_save_dir.mkdir(parents=True, exist_ok=True)
                deep_ssm_path = self.model_save_dir / "deep_ssm"
                self.deep_ssm_model.save(deep_ssm_path.resolve().as_posix())

        if not self.lg_ssm_model.is_fitted:
            self.lg_ssm_model.fit(train_x[FRAC_FEATS])
            # ä¿å­˜ lg ssm æ¨¡å‹
            if self.model_save_dir:
                self.model_save_dir.mkdir(parents=True, exist_ok=True)
                lg_ssm_path = self.model_save_dir / "lg_ssm"
                self.lg_ssm_model.save(lg_ssm_path.resolve().as_posix())

    def get_deep_ssm_features(self, train_x):
        feat_deep_ssm = self.deep_ssm_model.transform(train_x[FRAC_FEATS])
        df_deep_ssm = pd.DataFrame(
            feat_deep_ssm,
            columns=[f"deep_ssm_{i}" for i in range(feat_deep_ssm.shape[1])],
            index=train_x.index,
        )
        return df_deep_ssm

    def get_lg_ssm_features(self, train_x):
        feat_lg_ssm = self.lg_ssm_model.transform(train_x[FRAC_FEATS])
        df_lg_ssm = pd.DataFrame(
            feat_lg_ssm,
            columns=[f"lg_ssm_{i}" for i in range(feat_lg_ssm.shape[1])],
            index=train_x.index,
        )
        return df_lg_ssm

    def get_all_features(self, train_x):
        # ğŸ”§ ä½¿ç”¨å†…å®¹å“ˆå¸Œè¿›è¡Œå¯é çš„ç¼“å­˜æ£€æµ‹ï¼ˆæ›¿ä»£ä¸å¯é çš„ id()ï¼‰
        current_hash = self._compute_data_hash(train_x)
        if (
            self._cached_all_features is not None
            and self._cached_train_x_hash == current_hash
        ):
            return self._cached_all_features

        self.fit(train_x)
        df_deep_ssm = self.get_deep_ssm_features(train_x)
        lg_ssm_features = self.get_lg_ssm_features(train_x)

        # ğŸ”§ ä½¿ç”¨é¢„åˆ†é… numpy æ•°ç»„æ›¿ä»£ pd.concatï¼Œå‡å°‘å†…å­˜åˆ†é…
        n_rows = len(train_x)
        n_cols_total = (
            df_deep_ssm.shape[1] + lg_ssm_features.shape[1] + train_x.shape[1]
        )

        # é¢„åˆ†é…ç»“æœæ•°ç»„ï¼ˆä½¿ç”¨ float32 èŠ‚çœå†…å­˜ï¼‰
        result_data = np.empty((n_rows, n_cols_total), dtype=np.float32)

        # ç›´æ¥èµ‹å€¼ï¼Œé¿å…ä¸­é—´å‰¯æœ¬
        col_offset = 0
        result_data[:, col_offset : col_offset + df_deep_ssm.shape[1]] = (
            df_deep_ssm.values
        )
        col_offset += df_deep_ssm.shape[1]
        result_data[:, col_offset : col_offset + lg_ssm_features.shape[1]] = (
            lg_ssm_features.values
        )
        col_offset += lg_ssm_features.shape[1]
        result_data[:, col_offset:] = train_x.values

        # æ„å»ºåˆ—ååˆ—è¡¨
        columns = (
            list(df_deep_ssm.columns)
            + list(lg_ssm_features.columns)
            + list(train_x.columns)
        )

        df = pd.DataFrame(result_data, index=train_x.index, columns=columns)

        # æ˜¾å¼åˆ é™¤ä¸­é—´å¯¹è±¡ï¼Œé‡Šæ”¾å†…å­˜
        del df_deep_ssm, lg_ssm_features, result_data
        gc.collect()

        # ç¼“å­˜ç»“æœ
        self._cached_all_features = df
        self._cached_train_x_hash = current_hash
        return df

    def get_all_features_no_fit(self, train_x):
        """è·å–æ‰€æœ‰ç‰¹å¾ä½†ä¸é‡æ–°è®­ç»ƒæ¨¡å‹ï¼Œé€‚ç”¨äºå·²åŠ è½½æ¨¡å‹çš„æƒ…å†µ"""
        df_deep_ssm = self.get_deep_ssm_features(train_x)
        lg_ssm_features = self.get_lg_ssm_features(train_x)

        # ğŸ”§ ä½¿ç”¨é¢„åˆ†é…æ•°ç»„æ›¿ä»£ pd.concat
        n_rows = len(train_x)
        n_cols_total = (
            df_deep_ssm.shape[1] + lg_ssm_features.shape[1] + train_x.shape[1]
        )
        result_data = np.empty((n_rows, n_cols_total), dtype=np.float32)

        col_offset = 0
        result_data[:, col_offset : col_offset + df_deep_ssm.shape[1]] = (
            df_deep_ssm.values
        )
        col_offset += df_deep_ssm.shape[1]
        result_data[:, col_offset : col_offset + lg_ssm_features.shape[1]] = (
            lg_ssm_features.values
        )
        col_offset += lg_ssm_features.shape[1]
        result_data[:, col_offset:] = train_x.values

        columns = (
            list(df_deep_ssm.columns)
            + list(lg_ssm_features.columns)
            + list(train_x.columns)
        )
        df = pd.DataFrame(result_data, index=train_x.index, columns=columns)

        del df_deep_ssm, lg_ssm_features, result_data
        return df

    def select_features(self, train_x, train_y) -> list[str]:
        _selector = self.selector
        df_feat = self.get_all_features(train_x)
        _selector.fit(df_feat, train_y)
        res = pd.Series(_selector.relevance_, index=_selector.variables_).sort_values(
            ascending=False
        )
        feature_names = res[res > 0].index.tolist()
        return feature_names

    def clear_cache(self):
        """ğŸ”§ æ¸…ç†ç¼“å­˜çš„ç‰¹å¾æ•°æ®å’Œæ¨¡å‹çŠ¶æ€ï¼Œé‡Šæ”¾å†…å­˜"""
        self._cached_all_features = None
        self._cached_train_x_hash = None

        # æ¸…ç† SSM æ¨¡å‹çš„æ¢¯åº¦ç¼“å­˜ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if hasattr(self, "deep_ssm_model") and self.deep_ssm_model is not None:
            if hasattr(self.deep_ssm_model, "model") and hasattr(
                self.deep_ssm_model.model, "zero_grad"
            ):
                self.deep_ssm_model.model.zero_grad(set_to_none=True)

        if hasattr(self, "lg_ssm_model") and self.lg_ssm_model is not None:
            if hasattr(self.lg_ssm_model, "model") and hasattr(
                self.lg_ssm_model.model, "zero_grad"
            ):
                self.lg_ssm_model.model.zero_grad(set_to_none=True)

        gc.collect()
