import matplotlib.pyplot as plt
import numpy as np
import optuna
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from hmmlearn.hmm import GMMHMM
from jesse.helpers import timestamp_to_time
from plotly.subplots import make_subplots


def gmm_labeler_find_best_params(
    candles: np.ndarray, lag_n: int, verbose: bool = True
) -> dict:
    def objective(trial: optuna.Trial):
        close_arr = candles[:, 2]
        high_arr = candles[:, 3][lag_n:]
        low_arr = candles[:, 4][lag_n:]

        log_return = np.log(close_arr[1:] / close_arr[:-1])[lag_n - 1 :]
        log_return_L = np.log(close_arr[lag_n:] / close_arr[:-lag_n])
        HL_diff = np.log(high_arr / low_arr)

        X = np.column_stack([log_return_L, log_return, HL_diff])

        datelist = np.asarray(
            [pd.Timestamp(timestamp_to_time(i)) for i in candles[:, 0][lag_n:]]
        )
        closeidx = candles[:, 2][lag_n:]

        assert len(datelist) == len(closeidx)
        assert len(datelist) == len(X)

        try:
            gmm = GMMHMM(
                n_components=2,
                n_mix=3,
                covariance_type="diag",
                n_iter=369,
                random_state=trial.suggest_int("random_state", 0, 1000),
            )
            gmm.fit(X)
            latent_states_sequence = gmm.predict(X)
        except (ValueError, RuntimeError, np.linalg.LinAlgError) as e:
            # GMMæ‹Ÿåˆæˆ–é¢„æµ‹å¤±è´¥æ—¶ï¼Œè¿”å›ä¸€ä¸ªæ— æ•ˆå€¼è®©Optunaå¿½ç•¥è¿™ä¸ªtrial
            # ä½¿ç”¨è´Ÿæ— ç©·æˆ–NaNä¼šè®©Optunaè®¤ä¸ºè¿™ä¸ªtrialå¤±è´¥
            if verbose:
                print(f"GMM failed with error: {e}")
            return float("-inf")  # è¿”å›è´Ÿæ— ç©·ï¼Œå› ä¸ºæˆ‘ä»¬åœ¨maximize

        data = pd.DataFrame(
            {
                "datelist": datelist,
                "logreturn": log_return,
                "state": latent_states_sequence,
            }
        ).set_index("datelist")

        final_ret = 0
        for i in data["state"].unique():
            ret = data[data["state"] == i]["logreturn"].sum()
            final_ret += np.abs(ret)

        return final_ret

    if not verbose:
        optuna.logging.set_verbosity(optuna.logging.WARNING)

    study = optuna.create_study(
        direction="maximize",
        sampler=optuna.samplers.TPESampler(n_startup_trials=10),
    )
    study.optimize(objective, n_trials=25)

    # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„trial
    if (
        len(
            [
                t
                for t in study.trials
                if t.value is not None and t.value != float("-inf")
            ]
        )
        == 0
    ):
        # å¦‚æœæ‰€æœ‰trialéƒ½å¤±è´¥äº†ï¼Œè¿”å›ä¸€ä¸ªé»˜è®¤çš„random_state
        if verbose:
            print("Warning: All GMM trials failed, using default random_state=42")
        return {"random_state": 369}

    best_params = study.best_params

    # ğŸ”§ æ˜¾å¼æ¸…ç† Optuna studyï¼Œé˜²æ­¢å†…å­˜æ³„æ¼
    del study
    gc.collect()

    return best_params


class GMMLabeler:
    def __init__(self, candles: np.ndarray, lag_n: int, verbose: bool = True):
        self.lag_n = lag_n

        random_state = gmm_labeler_find_best_params(candles, lag_n, verbose)[
            "random_state"
        ]
        self.gmm_model = GMMHMM(
            n_components=2,
            n_mix=3,
            covariance_type="diag",
            n_iter=369,
            random_state=random_state,
        )

        close_arr = candles[:, 2]
        high_arr = candles[:, 3][lag_n:]
        low_arr = candles[:, 4][lag_n:]

        self._datelist = np.asarray(
            [pd.Timestamp(timestamp_to_time(i)) for i in candles[:, 0][lag_n:]]
        )
        self._closeidx = candles[:, 2][lag_n:]

        self.log_return = np.log(close_arr[1:] / close_arr[:-1])[lag_n - 1 :]
        log_return_L = np.log(close_arr[lag_n:] / close_arr[:-lag_n])
        HL_diff = np.log(high_arr / low_arr)
        X = np.column_stack([log_return_L, self.log_return, HL_diff])

        self.gmm_model.fit(X)
        self.latent_states_sequence = self.gmm_model.predict(X)  ### ç¡¬æ ‡ç­¾
        self.state_probabilities = self.gmm_model.predict_proba(X)  ### æ¦‚ç‡æ ‡ç­¾

        # Label_b: assign each return to the previous state's label.
        state_0_mask = np.append(0, (self.latent_states_sequence == 0)[:-1])
        state_1_mask = np.append(0, (self.latent_states_sequence == 1)[:-1])
        state_0_return = (self.log_return * state_0_mask).sum()
        state_1_return = (self.log_return * state_1_mask).sum()
        if state_0_return > state_1_return:
            self.latent_states_sequence = 1 - self.latent_states_sequence
            self.state_probabilities = self.state_probabilities[:, ::-1]
        self.buy_state = 1

    def plot_label_on_candles(self):
        """
        åœ¨èœ¡çƒ›å›¾ä¸Šç»˜åˆ¶æ ‡ç­¾
        """
        n_states = self.gmm_model.n_components
        # ä¸»å›¾ + æ¯ä¸ªéšå«çŠ¶æ€ä¸€ä¸ªæ¦‚ç‡å‰¯å›¾
        prob_heights = [0.4 / n_states] * n_states
        row_heights = [0.6] + prob_heights
        subplot_titles = ["éšå«çŠ¶æ€åºåˆ—"] + [f"P(state={i})" for i in range(n_states)]

        fig = make_subplots(
            rows=1 + n_states,
            cols=1,
            shared_xaxes=True,
            row_heights=row_heights,
            vertical_spacing=0.06,
            subplot_titles=tuple(subplot_titles),
        )
        colors = px.colors.qualitative.Plotly

        for i in range(n_states):
            state = self.latent_states_sequence == i
            fig.add_trace(
                go.Scatter(
                    x=self._datelist[state],
                    y=self._closeidx[state],
                    mode="markers",
                    name=f"latent state {i}",
                    marker=dict(color=colors[i % len(colors)], size=4),
                    legendgroup=f"state_{i}",
                    showlegend=True,
                ),
                row=1,
                col=1,
            )

        # æ¦‚ç‡å‰¯å›¾ï¼šä¸ºæ¯ä¸ªéšå«çŠ¶æ€å•ç‹¬ç»˜åˆ¶æ¦‚ç‡çº¿å›¾æˆ–é¢ç§¯å›¾
        for i in range(n_states):
            fig.add_trace(
                go.Scatter(
                    x=self._datelist,
                    y=self.state_probabilities[:, i],
                    name=f"P(state={i})",
                    mode="lines",
                    fill="tozeroy",  # å¡«å……åˆ°0ï¼Œå½¢æˆé¢ç§¯å›¾
                    line=dict(color=colors[i % len(colors)], width=1),
                    fillcolor=colors[i % len(colors)],
                    opacity=0.7,
                    legendgroup=f"state_{i}",
                    showlegend=False,  # ä¸ä¸»å›¾åŒç»„é¢œè‰²ï¼Œä¸é‡å¤å›¾ä¾‹
                ),
                row=2 + i,
                col=1,
            )

        fig.update_yaxes(title_text="æ”¶ç›˜ä»·", row=1, col=1)
        for i in range(n_states):
            fig.update_yaxes(title_text=f"P(state={i})", range=[0, 1], row=2 + i, col=1)
        # ä»…åœ¨æœ€åº•éƒ¨å­å›¾è®¾ç½®æ—¶é—´è½´æ ‡é¢˜
        fig.update_xaxes(title_text="æ—¶é—´", row=1 + n_states, col=1)

        fig.update_layout(
            title="éšå«çŠ¶æ€åºåˆ—ä¸çŠ¶æ€æ¦‚ç‡",
            showlegend=True,
            hovermode="x unified",  # ç»Ÿä¸€çš„æ‚¬åœæ¨¡å¼ï¼Œæ›´å¥½åœ°æ˜¾ç¤ºå¤šä¸ªå­å›¾çš„æ•°æ®
        )

        fig.show()

    def plot_label_returns(self):
        """
        ç»˜åˆ¶æ ‡ç­¾æ”¶ç›Š
        """
        data = pd.DataFrame(
            {
                "datelist": self._datelist,
                "logreturn": self.log_return,
                "state": self.latent_states_sequence,
            }
        ).set_index("datelist")

        for i in range(self.gmm_model.n_components):
            state = self.latent_states_sequence == i
            idx = np.append(0, state[:-1])
            ret = data.logreturn.multiply(idx, axis=0).sum()
            count = int(idx.sum())
            print(f"state {i} ({count}) return: {ret:.6%}")

        plt.figure(figsize=(20, 8))
        for i in range(self.gmm_model.n_components):
            state = self.latent_states_sequence == i
            idx = np.append(0, state[:-1])
            data[f"state {i}_return"] = data.logreturn.multiply(idx, axis=0)
            plt.plot(
                np.exp(data[f"state {i}_return"].cumsum()),
                label=f"latent_state {i}",
            )
            plt.legend(loc="upper left")
            plt.grid(1)

        plt.show()

    @property
    def label_hard_state(self):
        """
        å¤šç©ºäºŒåˆ†ç±»ç¡¬æ ‡ç­¾ï¼Œç”¨äºåˆ†ç±»æ¨¡å‹
        """
        return (self.latent_states_sequence == self.buy_state).astype(int)

    @property
    def label_double_prob(self):
        """
        åŒæ¦‚ç‡æ ‡ç­¾ï¼Œå®Œæ•´æ¦‚ç‡åˆ†å¸ƒï¼Œç”¨äºå¤šæ ‡ç­¾å›å½’
        """
        buy_prob = self.state_probabilities[:, self.buy_state]
        sell_prob = self.state_probabilities[:, 1 - self.buy_state]
        return np.column_stack([sell_prob, buy_prob])

    @property
    def label_directional_prob(self):
        """
        å¸¦æ–¹å‘çš„åŸå§‹æ¦‚ç‡æ ‡ç­¾ï¼Œæ–¹å‘ + æ¦‚ç‡å¤§å°ï¼ˆéå¯¹ç§°ï¼‰ï¼Œç”¨äºå›å½’
        """
        return np.where(
            self.latent_states_sequence == self.buy_state,
            self.state_probabilities[:, self.buy_state],
            -self.state_probabilities[:, 1 - self.buy_state],
        )

    @property
    def label_direction_force(self):
        """
        æ–¹å‘å¼ºåº¦æ ‡ç­¾ï¼Œæ–¹å‘ + ç›¸å¯¹å¼ºåº¦ï¼ˆå¯¹ç§°ï¼‰ï¼Œç”¨äºå›å½’
        """
        return self.state_probabilities[:, self.buy_state] * 2 - 1
