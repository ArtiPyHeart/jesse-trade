{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T03:20:02.716751Z",
     "start_time": "2025-05-23T03:19:51.064927Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from jesse import helpers, research\n",
    "\n",
    "_, candles = research.get_candles(\n",
    "    \"Binance Perpetual Futures\",\n",
    "    \"BTC-USDT\",\n",
    "    \"1m\",\n",
    "    helpers.date_to_timestamp(\"2020-01-01\"),\n",
    "    helpers.date_to_timestamp(\"2025-06-18\"),\n",
    "    warmup_candles_num=0,\n",
    "    caching=False,\n",
    "    is_for_jesse=False,\n",
    ")\n",
    "\n",
    "candles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T03:20:08.170027Z",
     "start_time": "2025-05-23T03:20:08.134454Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save(\"data/btc_1m.npy\", candles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T06:57:14.043231Z",
     "start_time": "2025-06-16T06:57:13.880750Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "candles = np.load(\"data/btc_1m.npy\")\n",
    "candles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T06:59:51.692472Z",
     "start_time": "2025-06-16T06:57:18.139169Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from custom_indicators.toolbox.bar.fusion.v0 import FusionBarContainerV0\n",
    "\n",
    "bar_container = FusionBarContainerV0(max_bars=500000)\n",
    "bar_container.update_with_candles(candles)\n",
    "merged_bar = bar_container.get_fusion_bars()\n",
    "close_arr = merged_bar[:, 2]\n",
    "ret = np.log(close_arr[1:] / close_arr[:-1])\n",
    "standard = (ret - ret.mean()) / ret.std()\n",
    "kurtosis = stats.kurtosis(standard, axis=None, fisher=False, nan_policy=\"omit\")\n",
    "kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T07:00:12.929855Z",
     "start_time": "2025-06-16T07:00:09.317648Z"
    }
   },
   "outputs": [],
   "source": [
    "from custom_indicators.utils.plot import plot_kde\n",
    "\n",
    "L = 5\n",
    "\n",
    "plot_kde(merged_bar[:, 2], lag=L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T07:00:55.392671Z",
     "start_time": "2025-06-16T07:00:16.984861Z"
    }
   },
   "outputs": [],
   "source": [
    "from hmmlearn.hmm import GMMHMM\n",
    "import pandas as pd\n",
    "import optuna\n",
    "\n",
    "from jesse.helpers import timestamp_to_time\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial):\n",
    "    mix = 3  ### GMM mix参数\n",
    "\n",
    "    close_arr = merged_bar[:, 2]\n",
    "    high_arr = merged_bar[:, 3][L:]\n",
    "    low_arr = merged_bar[:, 4][L:]\n",
    "\n",
    "    log_return = np.log(close_arr[1:] / close_arr[:-1])[L - 1 :]\n",
    "    log_return_L = np.log(close_arr[L:] / close_arr[:-L])\n",
    "    HL_diff = np.log(high_arr / low_arr)\n",
    "\n",
    "    X = np.column_stack([HL_diff, log_return_L, log_return])\n",
    "\n",
    "    datelist = np.asarray(\n",
    "        [pd.Timestamp(timestamp_to_time(i)) for i in merged_bar[:, 0][L:]]\n",
    "    )\n",
    "    closeidx = merged_bar[:, 2][L:]\n",
    "\n",
    "    assert len(datelist) == len(closeidx)\n",
    "    assert len(datelist) == len(X)\n",
    "\n",
    "    gmm = GMMHMM(\n",
    "        n_components=2,\n",
    "        n_mix=mix,\n",
    "        covariance_type=\"diag\",\n",
    "        n_iter=1000,\n",
    "        # weights_prior=2,\n",
    "        means_weight=0.5,\n",
    "        random_state=trial.suggest_int(\"random_state\", 0, 1000),\n",
    "    )\n",
    "    gmm.fit(X)\n",
    "    latent_states_sequence = gmm.predict(X)\n",
    "    data = pd.DataFrame(\n",
    "        {\n",
    "            \"datelist\": datelist,\n",
    "            \"logreturn\": log_return,\n",
    "            \"state\": latent_states_sequence,\n",
    "        }\n",
    "    ).set_index(\"datelist\")\n",
    "\n",
    "    final_ret = 0\n",
    "    for i in data[\"state\"].unique():\n",
    "        ret = data[data[\"state\"] == i][\"logreturn\"].sum()\n",
    "        final_ret += np.abs(ret)\n",
    "\n",
    "    return final_ret\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=optuna.samplers.TPESampler(),\n",
    ")\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T07:00:55.405211Z",
     "start_time": "2025-06-16T07:00:55.402398Z"
    }
   },
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T07:01:01.750996Z",
     "start_time": "2025-06-16T07:01:00.184035Z"
    }
   },
   "outputs": [],
   "source": [
    "from hmmlearn.hmm import GMMHMM  # noqa\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import pandas as pd  # noqa\n",
    "\n",
    "from jesse.helpers import timestamp_to_time  # noqa\n",
    "\n",
    "mix = 3  ### GMM mix参数\n",
    "\n",
    "close_arr = merged_bar[:, 2]\n",
    "high_arr = merged_bar[:, 3][L:]\n",
    "low_arr = merged_bar[:, 4][L:]\n",
    "\n",
    "log_return = np.log(close_arr[1:] / close_arr[:-1])[L - 1 :]\n",
    "log_return_L = np.log(close_arr[L:] / close_arr[:-L])\n",
    "HL_diff = np.log(high_arr / low_arr)\n",
    "\n",
    "X = np.column_stack([HL_diff, log_return_L, log_return])\n",
    "\n",
    "datelist = np.asarray(\n",
    "    [pd.Timestamp(timestamp_to_time(i)) for i in merged_bar[:, 0][L:]]\n",
    ")\n",
    "closeidx = merged_bar[:, 2][L:]\n",
    "\n",
    "assert len(datelist) == len(closeidx)\n",
    "assert len(datelist) == len(X)\n",
    "\n",
    "gmm = GMMHMM(\n",
    "    n_components=2,\n",
    "    n_mix=mix,\n",
    "    covariance_type=\"diag\",\n",
    "    n_iter=1000,\n",
    "    # weights_prior=2,\n",
    "    means_weight=0.5,\n",
    "    random_state=study.best_params[\"random_state\"],\n",
    ")\n",
    "gmm.fit(X)\n",
    "latent_states_sequence = gmm.predict(X)\n",
    "\n",
    "print(np.unique(latent_states_sequence, return_counts=True))\n",
    "\n",
    "fig = go.Figure()\n",
    "colors = px.colors.qualitative.Plotly\n",
    "\n",
    "for i in range(gmm.n_components):\n",
    "    state = latent_states_sequence == i\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=datelist[state],\n",
    "            y=closeidx[state],\n",
    "            mode=\"markers\",\n",
    "            name=f\"latent state {i}\",\n",
    "            marker=dict(color=colors[i % len(colors)], size=4),\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"隐含状态序列\",\n",
    "    xaxis_title=\"时间\",\n",
    "    yaxis_title=\"收盘价\",\n",
    "    # width=1400,\n",
    "    # height=600,\n",
    "    showlegend=True,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T07:01:25.940371Z",
     "start_time": "2025-06-16T07:01:25.649737Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "        \"datelist\": datelist,\n",
    "        \"logreturn\": log_return,\n",
    "        \"state\": latent_states_sequence,\n",
    "    }\n",
    ").set_index(\"datelist\")\n",
    "\n",
    "for i in data[\"state\"].unique():\n",
    "    ret = data[data[\"state\"] == i][\"logreturn\"].sum()\n",
    "    count = data[data[\"state\"] == i].shape[0]\n",
    "    print(f\"state {i} ({count}) return: {ret:.6%}\")\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "for i in range(gmm.n_components):\n",
    "    state = latent_states_sequence == i\n",
    "    idx = np.append(0, state[1:])\n",
    "    data[\"state %d_return\" % i] = data.logreturn.multiply(idx, axis=0)\n",
    "    plt.plot(np.exp(data[\"state %d_return\" % i].cumsum()), label=\"latent_state %d\" % i)\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.grid(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T07:01:33.702059Z",
     "start_time": "2025-06-16T07:01:33.699236Z"
    }
   },
   "outputs": [],
   "source": [
    "assert len(merged_bar[L:]) == len(latent_states_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T07:01:34.522484Z",
     "start_time": "2025-06-16T07:01:34.516253Z"
    }
   },
   "outputs": [],
   "source": [
    "# 保存merged bar, 去除最后一个bar，因为需要label前移一位\n",
    "print(merged_bar[:-1].shape)\n",
    "np.save(\"data/merged_bar.npy\", merged_bar[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T07:01:49.956536Z",
     "start_time": "2025-06-16T07:01:49.950374Z"
    }
   },
   "outputs": [],
   "source": [
    "# 上涨下跌统一打标的情况\n",
    "\n",
    "label = (latent_states_sequence == 1).astype(int)\n",
    "print(np.unique(label, return_counts=True))\n",
    "np.save(\"data/side_label.npy\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上涨下跌分别打标的情况\n",
    "\n",
    "# label_long = (latent_states_sequence == 1).astype(int)\n",
    "# print(np.unique(label_long, return_counts=True))\n",
    "# np.save(\"data/side_label_long.npy\", label_long)\n",
    "\n",
    "# label_short = (latent_states_sequence == 0).astype(int)\n",
    "# print(np.unique(label_short, return_counts=True))\n",
    "# np.save(\"data/side_label_short.npy\", label_short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T14:25:12.115241Z",
     "start_time": "2025-06-08T14:25:05.332966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34487,)\n",
      "(array([-1,  1]), array([15541, 18946]))\n",
      "(array([-1,  1]), array([15551, 18936]))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from strategies.BinanceBtcEntropyBarV1.config import SIDE\n",
    "from strategies.BinanceBtcEntropyBarV1.config import get_side_model\n",
    "\n",
    "side_model = get_side_model(False)\n",
    "\n",
    "df_features = pd.read_parquet(\"data/features.parquet\")\n",
    "\n",
    "side_res = side_model.predict(df_features[SIDE])\n",
    "\n",
    "side_pred_label = np.where(side_res > 0.5, 1, -1)\n",
    "print(side_pred_label.shape)\n",
    "\n",
    "print(np.unique(side_pred_label, return_counts=True))\n",
    "\n",
    "side_label = np.load(\"data/side_label.npy\")\n",
    "side_label = np.where(side_label == 1, 1, -1)\n",
    "\n",
    "len_gap = len(side_label) - len(side_pred_label)\n",
    "side_label = side_label[len_gap:]\n",
    "\n",
    "print(np.unique(side_label, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-08T14:29:43.851087Z",
     "start_time": "2025-06-08T14:29:43.830919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34487,)\n",
      "(34487,)\n",
      "(array([0, 1]), array([  266, 34221]))\n",
      "(array([0, 1]), array([  311, 34176]))\n"
     ]
    }
   ],
   "source": [
    "meta_label = (side_pred_label == side_label).astype(int)\n",
    "print(meta_label.shape)\n",
    "\n",
    "merged_bar = np.load(\"data/merged_bar.npy\")\n",
    "log_ret = np.log(merged_bar[1:, 2] / merged_bar[:-1, 2])\n",
    "len_gap = len(log_ret) - len(side_pred_label)\n",
    "log_ret = log_ret[len_gap:]\n",
    "print(log_ret.shape)\n",
    "\n",
    "# start_idx = 0\n",
    "# cumsum_ret = 0\n",
    "# for idx, (i, r) in enumerate(zip(side_pred_label[:-1], log_ret[:-1])):\n",
    "#     if i == 1:\n",
    "#         if idx == 0:\n",
    "#             # 开始持仓\n",
    "#             start_idx = idx\n",
    "#         elif side_pred_label[idx - 1] == -1:\n",
    "#             # 反向持仓，先结算收益\n",
    "#             if cumsum_ret > 0:\n",
    "#                 meta_label[start_idx:idx] = 1\n",
    "#             cumsum_ret = 0\n",
    "#             start_idx = idx\n",
    "#         else:\n",
    "#             # 继续持仓\n",
    "#             cumsum_ret += r\n",
    "#     elif i == -1:\n",
    "#         if idx == 0:\n",
    "#             # 开始持仓\n",
    "#             start_idx = idx\n",
    "#         elif side_pred_label[idx - 1] == 1:\n",
    "#             # 反向持仓，先结算收益\n",
    "#             if cumsum_ret < 0:\n",
    "#                 meta_label[start_idx:idx] = 1\n",
    "#             cumsum_ret = 0\n",
    "#             start_idx = idx\n",
    "#         else:\n",
    "#             # 继续持仓\n",
    "#             cumsum_ret += r\n",
    "#     else:\n",
    "#         raise ValueError(f\"side_pred_label[{idx}] = {i} is not valid\")\n",
    "\n",
    "\n",
    "print(np.unique(meta_label, return_counts=True))\n",
    "\n",
    "# meta label复核：对于所有meta label = 1的情况，结合side_pred_label看是否真的盈利\n",
    "TRADE_FEE = 0.05 / 100\n",
    "\n",
    "start_idx = 0\n",
    "cumsum_ret = 0\n",
    "for idx, (meta, side, ret) in enumerate(zip(meta_label, side_pred_label, log_ret)):\n",
    "    if meta == 1:\n",
    "        if idx > 0 and meta_label[idx - 1] == 0:\n",
    "            # 开始持仓\n",
    "            start_idx = idx\n",
    "            cumsum_ret -= TRADE_FEE\n",
    "        else:\n",
    "            # 继续持仓\n",
    "            cumsum_ret += ret * side\n",
    "    elif meta == 0:\n",
    "        if idx > 0 and meta_label[idx - 1] == 1:\n",
    "            # 结束持仓\n",
    "            cumsum_ret += ret * side - TRADE_FEE\n",
    "            end_idx = idx\n",
    "            if cumsum_ret < 0:\n",
    "                # 如果收益为负，则认为判断错误\n",
    "                assert start_idx < end_idx, \"start_idx must be less than end_idx\"\n",
    "                meta_label[start_idx:end_idx] = 0\n",
    "            # 重置收益\n",
    "            cumsum_ret = 0\n",
    "            start_idx = 0\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "print(np.unique(meta_label, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T14:22:18.045816Z",
     "start_time": "2025-04-13T14:22:18.037477Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save(\"data/label_meta.npy\", meta_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jesse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
