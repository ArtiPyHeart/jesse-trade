{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.show_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T13:01:35.346269Z",
     "start_time": "2025-05-09T13:01:19.579608Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from jesse import helpers, research\n",
    "\n",
    "_, candles = research.get_candles(\n",
    "    \"Binance Perpetual Futures\",\n",
    "    \"BTC-USDT\",\n",
    "    \"1m\",\n",
    "    helpers.date_to_timestamp(\"2020-01-01\"),\n",
    "    helpers.date_to_timestamp(\"2025-06-16\"),\n",
    "    warmup_candles_num=0,\n",
    "    caching=False,\n",
    "    is_for_jesse=False,\n",
    ")\n",
    "\n",
    "candles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T13:01:44.076027Z",
     "start_time": "2025-05-09T13:01:44.047434Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save(\"data/btc_1m.npy\", candles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T13:01:45.233940Z",
     "start_time": "2025-05-09T13:01:45.216272Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2869920, 6)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "candles = np.load(\"data/btc_1m.npy\")\n",
    "candles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([          nan,           nan,           nan, ..., 6004.25018203,\n",
       "       5995.85352277, 6022.51133832])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from custom_indicators.prod_indicator.diff.fracdiff import (\n",
    "    frac_diff_candles,\n",
    ")\n",
    "\n",
    "res = frac_diff_candles(\n",
    "    candles[-10000:], source_type=\"close\", window=100, d=0.5, sequential=True\n",
    ")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from jesse.utils import numpy_candles_to_dataframe\n",
    "\n",
    "df = numpy_candles_to_dataframe(candles)\n",
    "df[\"hlret\"] = np.log(df[\"high\"] / df[\"low\"])\n",
    "ret_list = []\n",
    "for i in range(1, 150):\n",
    "    ret_series = np.log(df[\"close\"] / df[\"close\"].shift(i))\n",
    "    ret_series.name = f\"ret{i}\"\n",
    "    ret_list.append(ret_series)\n",
    "df = pd.concat([df, pd.concat(ret_list, axis=1)], axis=1)\n",
    "del ret_list\n",
    "df = df[df[\"ret149\"].notna()]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_indicators.utils.plot import find_kde_cross\n",
    "\n",
    "target = df[\"ret149\"].to_numpy()\n",
    "roots = find_kde_cross(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = df[\"ret149\"].copy().sort_values()\n",
    "label = ((series <= roots[0]) | (series >= roots[-1])).astype(int)\n",
    "label.sort_index(inplace=True)\n",
    "label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gplearn.fitness import make_fitness\n",
    "from gplearn.genetic import SymbolicClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def gp_f1(y, y_pred, w):\n",
    "    y_pred_labels = (y_pred > 0.5).astype(int)\n",
    "    return f1_score(y, y_pred_labels, sample_weight=w)\n",
    "\n",
    "\n",
    "my_custom_f1_fitness = make_fitness(function=gp_f1, greater_is_better=True)\n",
    "\n",
    "cols = [f\"ret{i}\" for i in range(1, 150)] + [\"hlret\", \"volume\"]\n",
    "\n",
    "est_gp = SymbolicClassifier(\n",
    "    metric=my_custom_f1_fitness,\n",
    "    population_size=5000,\n",
    "    stopping_criteria=0,\n",
    "    function_set=[\"add\", \"sub\", \"sqrt\", \"log\", \"abs\", \"neg\", \"max\", \"min\"],\n",
    "    p_crossover=0.7,\n",
    "    p_subtree_mutation=0.05,\n",
    "    p_hoist_mutation=0.05,\n",
    "    p_point_mutation=0.05,\n",
    "    max_samples=1,\n",
    "    parsimony_coefficient=0.005,\n",
    "    class_weight=\"balanced\",\n",
    "    feature_names=cols,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "\n",
    "est_gp.fit(df[cols], label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred = est_gp.predict(df[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(label_pred, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "for lag in range(10, 300):\n",
    "    log_ret = np.log(candles[lag:, 2] / candles[:-lag, 2])\n",
    "    standard = (log_ret - log_ret.mean()) / log_ret.std()\n",
    "    kurtosis = stats.kurtosis(standard, axis=None, fisher=False, nan_policy=\"omit\")\n",
    "    print(f\"{lag = }: {kurtosis = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-09T06:07:24.959355Z",
     "start_time": "2025-05-09T05:36:29.164062Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from custom_indicators.toolbox.entropy.apen_sampen import sample_entropy\n",
    "\n",
    "LAG = 159\n",
    "log_ret = [\n",
    "    np.log(candles[i, 2] / candles[-LAG + i : i, 2]) for i in range(LAG, len(candles))\n",
    "]\n",
    "with Pool(processes=os.cpu_count() - 1) as pool:\n",
    "    entropy_array = list(\n",
    "        tqdm(pool.imap(sample_entropy, log_ret), total=len(log_ret), desc=\"计算样本熵\")\n",
    "    )\n",
    "\n",
    "candles = candles[LAG:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算threshold\n",
    "DURATION = 298\n",
    "\n",
    "threshold = np.sum(entropy_array) / (len(candles) // DURATION)\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bar import build_bar_by_cumsum\n",
    "\n",
    "merged_bar = build_bar_by_cumsum(candles, entropy_array, threshold)\n",
    "merged_bar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_indicators.utils.plot import plot_kde\n",
    "\n",
    "plot_kde(merged_bar[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jesse.indicators as ta\n",
    "import numpy as np\n",
    "\n",
    "raw_candles = np.load(\"data/btc_1m.npy\")\n",
    "print(raw_candles.shape)\n",
    "candles = ta.heikin_ashi_candles(raw_candles, sequential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import jesse.indicators as ta\n",
    "import optuna\n",
    "from scipy import stats\n",
    "\n",
    "from bar import build_bar_by_cumsum\n",
    "from custom_indicators.toolbox.entropy.apen_sampen import sample_entropy\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    duration = trial.suggest_int(\"duration\", 60, 360)\n",
    "    lag = trial.suggest_int(\"lag\", 20, 360)\n",
    "    use_weight = trial.suggest_categorical(\"use_weight\", [True, False])\n",
    "    use_heikin_ashi = trial.suggest_categorical(\"use_heikin_ashi\", [True, False])\n",
    "\n",
    "    candles = np.load(\"data/btc_1m.npy\")\n",
    "    if use_heikin_ashi:\n",
    "        ha = ta.heikin_ashi_candles(candles, sequential=True)\n",
    "        candles[:, 1] = ha.open\n",
    "        candles[:, 2] = ha.close\n",
    "        candles[:, 3] = ha.high\n",
    "        candles[:, 4] = ha.low\n",
    "        candles = candles[1:]\n",
    "\n",
    "    log_ret = [\n",
    "        np.log(candles[i, 2] / candles[-lag + i : i, 2])\n",
    "        for i in range(lag, len(candles))\n",
    "    ]\n",
    "\n",
    "    if use_weight:\n",
    "        weight = np.flip(np.arange(1, len(log_ret[0]) + 1) / len(log_ret[0]))\n",
    "    else:\n",
    "        weight = np.ones(len(log_ret[0]))\n",
    "    log_ret = [log_ret[i] * weight for i in range(len(log_ret))]\n",
    "\n",
    "    with Pool(processes=os.cpu_count() - 1) as pool:\n",
    "        entropy_array = list(pool.map(sample_entropy, log_ret))\n",
    "    candles = candles[lag:]\n",
    "\n",
    "    threshold = np.sum(entropy_array) / (len(candles) // duration)\n",
    "    merged_bar = build_bar_by_cumsum(candles, entropy_array, threshold)\n",
    "    close_arr = merged_bar[:, 2]\n",
    "    ret = np.log(close_arr[1:] / close_arr[:-1])\n",
    "    standard = (ret - ret.mean()) / ret.std()\n",
    "    kurtosis = stats.kurtosis(standard, axis=None, fisher=False, nan_policy=\"omit\")\n",
    "    return kurtosis\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\",\n",
    "    pruner=optuna.pruners.HyperbandPruner(),\n",
    "    sampler=optuna.samplers.TPESampler(),\n",
    ")\n",
    "study.optimize(objective, n_trials=500, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from bar import (\n",
    "    build_dollar_bar,\n",
    "    estimate_dollar_bar_threshold,\n",
    ")\n",
    "\n",
    "candles = np.load(\"data/btc_1m.npy\")\n",
    "print(candles.shape)\n",
    "\n",
    "threshold = estimate_dollar_bar_threshold(candles, 300)\n",
    "print(threshold)\n",
    "\n",
    "dollar_bar = build_dollar_bar(candles, threshold)\n",
    "dollar_bar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_indicators.utils.plot import plot_kde\n",
    "\n",
    "plot_kde(dollar_bar[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T04:55:04.919853Z",
     "start_time": "2025-05-07T04:53:58.793636Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from bar import np_merge_bars\n",
    "\n",
    "N = int(candles.shape[0] / 240)\n",
    "\n",
    "for lag in [100, 140, 145, 146, 147, 148, 149, 150, 151, 160, 200, 250]:\n",
    "    print(f\"------------------{lag = }---------------------\")\n",
    "    if not Path(f\"data/btc_1m_m4h_lag_{lag}.npy\").exists():\n",
    "        new_candles = np_merge_bars(candles, N, lag=lag)\n",
    "        print(new_candles.shape)\n",
    "        np.save(f\"data/btc_1m_m4h_lag_{lag}.npy\", new_candles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from bar import np_merge_bars\n",
    "\n",
    "for t in [-10, 10]:\n",
    "    print(f\"------------------{t = }---------------------\")\n",
    "    N = int(candles.shape[0] / (4 * 60 + t))\n",
    "    path = Path(f\"data/btc_1m_m4h{t}_lag_149.npy\")\n",
    "    if not path.exists():\n",
    "        new_candles = np_merge_bars(candles, N, lag=149)\n",
    "        print(new_candles.shape)\n",
    "        np.save(path, new_candles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T03:03:11.438905Z",
     "start_time": "2025-05-06T03:03:09.896434Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from jesse.utils import numpy_candles_to_dataframe\n",
    "\n",
    "merged_bar = np.load(\"data/btc_1m_m4h_lag_149.npy\")\n",
    "df_merged_bar = numpy_candles_to_dataframe(merged_bar)\n",
    "df_merged_bar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T03:03:15.233494Z",
     "start_time": "2025-05-06T03:03:12.140163Z"
    }
   },
   "outputs": [],
   "source": [
    "from lightweight_charts import Chart\n",
    "\n",
    "chart = Chart()\n",
    "chart.set(df_merged_bar[[\"date\", \"open\", \"high\", \"low\", \"close\", \"volume\"]])\n",
    "chart.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T16:07:37.121345Z",
     "start_time": "2025-05-05T16:07:36.357783Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "lag 100: kurtosis = 46.53\n",
    "lag 140: kurtosis = 21.92\n",
    "lag 147: kurtosis = 21.76\n",
    "lag 148: kurtosis = 21.01\n",
    "lag 149: kurtosis = 20.64\n",
    "lag 150: kurtosis = 20.95\n",
    "lag 160: kurtosis = 24.14\n",
    "lag 200: kurtosis = 33.81\n",
    "\"\"\"\n",
    "\n",
    "merged_bar = np.load(\"data/btc_1m_m4h_lag_149.npy\")\n",
    "print(merged_bar.shape)\n",
    "plot_kde(merged_bar[:, 2], lag=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jesse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
